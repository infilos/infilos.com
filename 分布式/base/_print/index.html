<!doctype html><html lang=zh class=no-js>
<head>
<meta charset=utf-8>
<meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no">
<meta name=generator content="Hugo 0.88.1">
<meta name=ROBOTS content="INDEX, FOLLOW">
<link rel=canonical type=text/html href=/%E5%88%86%E5%B8%83%E5%BC%8F/base/>
<link rel="shortcut icon" href=/favicons/favicon.ico>
<link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180>
<link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16>
<link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32>
<link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36>
<link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48>
<link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72>
<link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96>
<link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144>
<link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192>
<title>基本构成 | infilos.com</title><meta property="og:title" content="基本构成">
<meta property="og:description" content="Infilos Wiki Website">
<meta property="og:type" content="website">
<meta property="og:url" content="/%E5%88%86%E5%B8%83%E5%BC%8F/base/"><meta property="og:site_name" content="infilos.com">
<meta itemprop=name content="基本构成">
<meta itemprop=description content="Infilos Wiki Website"><meta name=twitter:card content="summary">
<meta name=twitter:title content="基本构成">
<meta name=twitter:description content="Infilos Wiki Website">
<script type=application/javascript>var doNotTrack=!1;doNotTrack||(window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)},ga.l=+new Date,ga('create','UA-123062585-1','auto'),ga('send','pageview'))</script>
<script async src=https://www.google-analytics.com/analytics.js></script>
<link rel=preload href=/scss/main.min.847464b684a6e89d7276700a5c500c17ab494dd1755b2654a7b27d8b59e3347e.css as=style>
<link href=/scss/main.min.847464b684a6e89d7276700a5c500c17ab494dd1755b2654a7b27d8b59e3347e.css rel=stylesheet integrity>
<script src=/js/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<link rel=stylesheet href=https://cdn.jsdelivr.net/npm/docsearch.js@2/dist/cdn/docsearch.min.css>
</head>
<body class=td-section>
<header>
<nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar">
<a class=navbar-brand href=/>
<span class=navbar-logo><svg id="Capa_1" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" viewBox="0 0 512 512" style="enable-background:new 0 0 512 512"><path style="fill:#ffc107" d="M432.384 143.616c-4.165-4.164-10.917-4.164-15.083.0l-60.352 60.352c-4.164 4.165-4.164 10.917.0 15.083 21.187 20.463 54.951 19.876 75.413-1.311 19.962-20.668 19.962-53.435.0-74.102L432.384 143.616z"/><path style="fill:#607d8b" d="M42.667 277.334c-5.891.003-10.669-4.771-10.672-10.662-.002-4.338 2.623-8.245 6.64-9.882l234.667-96c5.455-2.233 11.687.38 13.92 5.835s-.38 11.687-5.835 13.92l-234.667 96C45.433 277.069 44.056 277.337 42.667 277.334z"/><path style="fill:#546e7a" d="M391.552 56.448l-32-32C343.938 8.745 322.689-.059 300.544.0h-3.755c-46.082.024-83.432 37.374-83.456 83.456v3.755c-.053 22.138 8.75 43.377 24.448 58.987l32 32c4.165 4.164 10.917 4.164 15.083.0L391.531 71.531C395.701 67.372 395.71 60.62 391.552 56.448z"/><path style="fill:#607d8b" d="M160 469.334c-3.279.006-6.379-1.497-8.405-4.075L34.261 315.926c-3.635-4.636-2.823-11.341 1.813-14.976s11.341-2.823 14.976 1.813l117.333 149.333c3.629 4.641 2.809 11.344-1.832 14.973C164.681 468.533 162.375 469.329 160 469.334z"/><path style="fill:#455a64" d="M487.467 86.848l-3.669-3.648c-37.687-36.557-97.71-36.197-134.955.811l-51.413 51.413c-36.996 37.25-37.357 97.263-.811 134.955l3.584 3.669c1.7 2.457 4.671 3.706 7.616 3.2 2.831.005 5.548-1.115 7.552-3.115l172.181-172.181c4.189-4.143 4.226-10.896.083-15.085-.028-.028-.055-.056-.083-.083L487.467 86.848z"/><g><path style="fill:#ffc107" d="M501.333 192H480c-5.891.0-10.667-4.776-10.667-10.667s4.776-10.667 10.667-10.667h21.333c5.891.0 10.667 4.776 10.667 10.667S507.225 192 501.333 192z"/><path style="fill:#ffc107" d="M394.667 298.667c-5.891.0-10.667-4.776-10.667-10.667v-21.333c0-5.891 4.776-10.667 10.667-10.667 5.891.0 10.667 4.776 10.667 10.667V288C405.333 293.891 400.558 298.667 394.667 298.667z"/><path style="fill:#ffc107" d="M480 277.334c-2.831.005-5.548-1.115-7.552-3.115l-21.333-21.333c-4.093-4.237-3.975-10.99.262-15.083 4.134-3.993 10.687-3.993 14.821.0l21.333 21.333c4.159 4.172 4.148 10.926-.024 15.085C485.514 276.209 482.815 277.327 480 277.334z"/></g><g><path style="fill:#455a64" d="M266.667 448H96c-29.455.0-53.333 23.878-53.333 53.333.0 5.891 4.776 10.667 10.667 10.667h256c5.891.0 10.667-4.776 10.667-10.667C320 471.878 296.122 448 266.667 448z"/><circle style="fill:#455a64" cx="32" cy="288" r="32"/></g><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/><g/></svg></span><span class=font-weight-bold>infilos.com</span>
</a>
<div class="collapse navbar-collapse" id=navbarSupportedContent>
<ul class="navbar-nav mr-auto">
<li class="nav-item dropdown" style=max-width:90px;min-width:10px>
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
基础
<span>+</span>
</a>
<div class=dropdown-menu aria-labelledby=navbarDropdown>
<a class=dropdown-item href=/%e5%9f%ba%e7%a1%80%e7%9f%a5%e8%af%86/%e6%93%8d%e4%bd%9c%e7%b3%bb%e7%bb%9f>操作系统</a>
<a class=dropdown-item href=/%e5%9f%ba%e7%a1%80%e7%9f%a5%e8%af%86/%e6%80%a7%e8%83%bd%e4%b9%8b%e6%ae%87>性能之殇</a>
<a class=dropdown-item href=/%e5%9f%ba%e7%a1%80%e7%9f%a5%e8%af%86/io%e6%a8%a1%e5%9e%8b>IO 模型</a>
<a class=dropdown-item href=/%e5%9f%ba%e7%a1%80%e7%9f%a5%e8%af%86/%e7%bd%91%e7%bb%9c%e5%9f%ba%e7%a1%80>网络基础</a>
<a class=dropdown-item href=/%e5%9f%ba%e7%a1%80%e7%9f%a5%e8%af%86/tcp-ip>TCP-IP</a>
<a class=dropdown-item href=/%e5%9f%ba%e7%a1%80%e7%9f%a5%e8%af%86/http>HTTP</a>
</div>
</li>
<li class="nav-item dropdown" style=max-width:90px;min-width:10px>
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
语言
<span>+</span>
</a>
<div class=dropdown-menu aria-labelledby=navbarDropdown>
<a class=dropdown-item href=/%e7%bc%96%e7%a8%8b%e8%af%ad%e8%a8%80/java>Java 编程</a>
<a class=dropdown-item href=/%e7%bc%96%e7%a8%8b%e8%af%ad%e8%a8%80/jvm-core>JVM 核心</a>
<a class=dropdown-item href=/%e7%bc%96%e7%a8%8b%e8%af%ad%e8%a8%80/jvm-concurrent>JVM 并发</a>
<a class=dropdown-item href=/%e7%bc%96%e7%a8%8b%e8%af%ad%e8%a8%80/scala>Scala 编程</a>
</div>
</li>
<li class="nav-item dropdown" style=max-width:90px;min-width:10px>
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
框架库
<span>+</span>
</a>
<div class=dropdown-menu aria-labelledby=navbarDropdown>
<a class=dropdown-item href=/%e6%a1%86%e6%9e%b6%e4%b8%8e%e5%ba%93/spring>Spring</a>
<a class=dropdown-item href=/%e6%a1%86%e6%9e%b6%e4%b8%8e%e5%ba%93/hikari>Hikari</a>
<a class=dropdown-item href=/%e6%a1%86%e6%9e%b6%e4%b8%8e%e5%ba%93/parboiled>Parboiled</a>
</div>
</li>
<li class="nav-item dropdown" style=max-width:90px;min-width:10px>
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
分布式
<span>+</span>
</a>
<div class=dropdown-menu aria-labelledby=navbarDropdown>
<a class=dropdown-item href=/%e5%88%86%e5%b8%83%e5%bc%8f/base>基本构成</a>
</div>
</li>
<li class="nav-item dropdown" style=max-width:90px;min-width:10px>
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
大数据
<span>+</span>
</a>
<div class=dropdown-menu aria-labelledby=navbarDropdown>
<a class=dropdown-item href=/%e5%ad%98%e5%82%a8%e7%b3%bb%e7%bb%9f>存储系统</a>
<a class=dropdown-item href=/%e6%9f%a5%e8%af%a2%e7%b3%bb%e7%bb%9f>查询系统</a>
<a class=dropdown-item href=/%e6%b6%88%e6%81%af%e7%b3%bb%e7%bb%9f>消息系统</a>
<a class=dropdown-item href=/%e5%a4%84%e7%90%86%e7%b3%bb%e7%bb%9f>处理系统</a>
<a class=dropdown-item href=/%e7%ae%a1%e7%90%86%e7%b3%bb%e7%bb%9f>管理系统</a>
</div>
</li>
<li class="nav-item dropdown" style=max-width:90px;min-width:10px>
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
中后台
<span>+</span>
</a>
<div class=dropdown-menu aria-labelledby=navbarDropdown>
<a class=dropdown-item href=/%e5%9f%ba%e7%a1%80%e8%ae%be%e6%96%bd>基础设施</a>
<a class=dropdown-item href=/%e4%ba%a4%e4%ba%92%e7%95%8c%e9%9d%a2>交互界面</a>
<a class=dropdown-item href=/%e4%b8%9a%e5%8a%a1%e7%b3%bb%e7%bb%9f>业务系统</a>
</div>
</li>
<li class="nav-item dropdown" style=max-width:90px;min-width:10px>
<a class="nav-link dropdown-toggle" href=# id=navbarDropdown role=button data-toggle=dropdown aria-haspopup=true aria-expanded=false>
模式架构
<span>+</span>
</a>
<div class=dropdown-menu aria-labelledby=navbarDropdown>
<a class=dropdown-item href=/%e6%a8%a1%e5%bc%8f%e6%9e%b6%e6%9e%84/design-pattern>设计模式</a>
<a class=dropdown-item href=/%e6%a8%a1%e5%bc%8f%e6%9e%b6%e6%9e%84/micro-service>微服务架构</a>
</div>
</li>
<li class=nav-item style=max-width:90px;min-width:10px>
<a class=nav-link href=/%e9%9d%a2%e8%af%95%e9%97%ae%e7%ad%94>
<span>面试</span>
</a>
</li>
<li class=nav-item style=max-width:90px;min-width:10px>
<a class=nav-link href=/%e7%ae%a1%e7%90%86%e8%b7%af%e5%be%84>
<span>管理</span>
</a>
</li>
<li class=nav-item style=max-width:90px;min-width:10px>
<a class=nav-link href=/%e5%bc%80%e6%ba%90%e9%a1%b9%e7%9b%ae>
<span>开源</span>
</a>
</li>
</ul>
<div class="form-inline my-2 my-lg-0">
<div class="nav-item nav-search-item my-2 my-md-0">
<input type=search class="form-control td-search-input" placeholder="&#xf002; 站内搜索…" aria-label=站内搜索… autocomplete=off>
</div>
</div>
</div>
</nav>
</header>
<div class="container-fluid td-outer">
<div class=td-main>
<div class="row flex-xl-nowrap">
<div class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none">
</div>
<div class="d-none d-xl-block col-xl-2 td-toc d-print-none">
</div>
<main class="col-12 col-md-9 col-xl-8 pl-md-5" role=main>
<div class=td-content>
<div class="pageinfo pageinfo-primary d-print-none">
<p>
这是本节的多页打印视图。
<a href=# onclick="return print(),!1">点击此处打印</a>.
</p><p>
<a href=/%E5%88%86%E5%B8%83%E5%BC%8F/base/>返回本页常规视图</a>.
</p>
</div>
<h1 class=title>基本构成</h1>
<ul>
<li>1: <a href=#pg-0f75d8b1d8f6eee87c962b23a42c48da>一致性模型</a></li>
<li>2: <a href=#pg-87c159b39f3a43bfbed4e9d852220aa2>ACID 隔离级别</a></li>
<li>3: <a href=#pg-833c5dab0c43fe6912b8924309db18a2>CAP</a></li>
<li>4: <a href=#pg-6a5395c7553310a95d78b1d98ba7a178>BASE</a></li>
<li>5: <a href=#pg-ddde0499c9ea9d037fe2d5463046b0f8>CALM</a></li>
<li>6: <a href=#pg-85b030129557bd100a1ee0d311e2a99b>Gossip</a></li>
<li>7: <a href=#pg-fe4f4b1b211faeadd32b75cc984329ce>CRDT</a></li>
<li>8: <a href=#pg-739b5ff30013dd87c474793ad2e1437d>2PC</a></li>
<li>9: <a href=#pg-62dc23672a681227dd62dfb84e0f21b1>3PC</a></li>
<li>10: <a href=#pg-b7cdad8f05e730f72e061037f7dc3c57>Paxos</a></li>
<li>11: <a href=#pg-2a687026a4d99f00caadb04ffa89c608>ZAB</a></li>
<li>12: <a href=#pg-26ac83d880caeb19690c75cfe250a72e>Raft</a></li>
<li>13: <a href=#pg-898151233fb238dfbda40e8b0930717c>分布式一致性</a></li>
<li>14: <a href=#pg-0abcc623d68d4f0a690005a87e3bea4d>分布式事务</a></li>
<li>15: <a href=#pg-32e7ec0298beb63dbf02b847a8c13b0a>分布式锁</a></li>
<li>16: <a href=#pg-cd6eab4d11b89cc125c95366a63cbaa1>一致性与共识算法</a></li>
<li>17: <a href=#pg-5972a917bbf5042578567f6c7c1d5c11>一致性哈希算法</a></li>
</ul>
<div class=content>
</div>
</div>
<div class=td-content>
<h1 id=pg-0f75d8b1d8f6eee87c962b23a42c48da>1 - 一致性模型</h1>
<h2 id=强一致性>强一致性</h2>
<p>当更新操作完成之后，任何多个后续进程或者线程的访问都会返回最新的更新过的值，直到这个数据被其他数据更新为止。</p>
<p>但是这种实现对性能影响较大，因为这意味着，只要上次的操作没有处理完，就不能让用户读取数据。</p>
<h2 id=弱一致性>弱一致性</h2>
<p>系统并不保证进程或者线程的访问都会返回最新更新过的值。系统在数据写入成功之后，不承诺立即可以读到最新写入的值，也不会具体的承诺多久之后可以读到。但会尽可能保证在某个时间级别(比如秒级别)之后，可以让数据达到一致性状态。</p>
<h2 id=最终一致性>最终一致性</h2>
<p>最终一致性也是弱一致性的一种，它无法保证数据更新后，所有后续的访问都能看到最新数值，而是需要一个时间，在这个时间之后可以保证这一点，而在这个时间内，数据也许是不一致的，这个系统无法保证强一致性的时间片段被称为“不一致窗口”。不一致窗口的时间长短取决于很多因素，比如备份数据的个数、网络传输延迟速度、系统负载等。</p>
<p>最终一致性在实际应用中又有多种变种：</p>
<table>
<thead>
<tr>
<th>类型</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>因果一致性</td>
<td>如果 A 进程在更新之后向 B 进程通知更新的完成，那么 B 的访问操作将会返回更新的值。而没有因果关系的 C 进程将会遵循最终一致性的规则（C 在不一致窗口内还是看到是旧值）。</td>
</tr>
<tr>
<td>读你所写一致性</td>
<td>因果一致性的特定形式。一个进程进行数据更新后，会给自己发送一条通知，该进程后续的操作都会以最新值作为基础，而其他的进程还是只能在不一致窗口之后才能看到最新值。</td>
</tr>
<tr>
<td>会话一致性</td>
<td>读你所写一致性的特定形式。进程在访问存储系统同一个会话内，系统保证该进程可以读取到最新之，但如果会话终止，重新连接后，如果此时还在不一致窗口内，还是可能读取到旧值。</td>
</tr>
<tr>
<td>单调读一致性</td>
<td>如果一个进程已经读取到一个特定值，那么该进程不会读取到该值以前的任何值。</td>
</tr>
<tr>
<td>单调写一致性</td>
<td>系统保证对同一个进程的写操作串行化。</td>
</tr>
</tbody>
</table>
<p>它们之间的关系如下图：</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/consistency.png style=display:block;width:80% alt=NAME align=center> </div>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-87c159b39f3a43bfbed4e9d852220aa2>2 - ACID 隔离级别</h1>
<p>强一致性ACID：</p>
<p>单机环境下我们对传统关系型数据库有苛刻的要求，由于存在网络的延迟和消息丢失，ACID 便是保证事务的原则，这四大原则甚至我们都不需要解释出来就耳熟能详了：</p>
<ul>
<li>Atomicity：原子性，一个事务中的所有操作，要么全部完成，要么全部不完成，不会结束在中间某个环节。</li>
<li>Consistency：一致性，在事务开始之前和事务结束以后，数据库的完整性没有被破坏。</li>
<li>Isolation：隔离性，数据库允许多个并发事务同时对其数据进行读写和修改的能力，隔离性可以防止多个事务并发执行时由于交叉执行而导致数据的不一致。</li>
<li>Durabilit：事务处理结束后，对数据的修改就是永久的，即便系统故障也不会丢失。</li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-833c5dab0c43fe6912b8924309db18a2>3 - CAP</h1>
<h2 id=定义>定义</h2>
<p><strong>C，Consistency</strong>，“all nodes see the same data at the same time”，即更新操作成功并返回客户端之后，所有节点在同一时间的数据完全一致。即所有节点拥有数据的最新版本。</p>
<p><strong>A，Availability</strong>，可用性：“Reads and writes always succed”，即服务一直可用，而且是正常响应时间。</p>
<p>对于一个可用性的分布式系统，每个非故障节点必须对每一个请求做出响应。即，该系统使用的任何算法必须最终终止。当同事要求分区容忍性时，这是一个很强的定义：即使是严重的网络错误，每个请求也必须能够终止。</p>
<p><strong>P，Partition Tolerance</strong>，分区容忍性：“the system continues to operate despite arbitrary message loss or failure of part of the system”，即系统容忍网络出现分区、分区之间网络不可达的情况。分区容忍性和可扩展性紧密相关。整体来说指的是，在遇到特定节点或网络分区故障时，仍然能够对外提供满足一致性和可用性的服务。</p>
<h3 id=p分区容忍性>P，分区容忍性</h3>
<p>什么是分区容忍性：</p>
<ul>
<li>一个分布式系统中，节点组成的网络本来应该是连通的。然而可能因为一些故障，使得有的节点之间不再连通，整个网络就分成了几块区域。数据就散步在这些不连通的区域中，就成为<strong>分区现象</strong>。</li>
<li>当一个数据项只在一个节点中保存，那么分区出现后，和这个节点不连通的部分就无法访问到该数据项。这时分区是<strong>无法容忍的</strong>。</li>
<li>提高分区容忍性的办法就是将一个数据项复制到多个节点上，那么在出现分区之后，这一数据项就可能分布在各个区域中，<strong>容忍性就提高了</strong>。</li>
<li>然而，要把数据复制到多个节点，就会带来一致性的问题，就是多个节点之上的数据可能是<strong>不一致</strong>的。</li>
<li>要保证一致，每次写操作就要等待所有节点写成功，则这种等待又会带来<strong>可用性</strong>问题。</li>
<li>总的来说就是，数据存在的节点越多，分区容忍性就越高，但是要复制的数据就越多，一致性就越难保证。为了保证一致性，更新所有节点数据的操作就会耗时更长，导致可用性降低。</li>
</ul>
<h2 id=不能同时满足的证明>不能同时满足的证明</h2>
<p>假设系统中有 5 个节点，N1~N5，N1/N2/N3 在物理机房 A，N4/N5 在物理机房 B。现在发生了网络分区，机房 A 和机房 B 之间的网络不互通。</p>
<p><strong>保证一致性</strong>：此时客户端在 A 机房写入数据，不能同步到 B 机房。写入失败。此时失去了可用性。</p>
<p><strong>保证可用性</strong>：数据在 A 机房的 N1~N3 节点都写入成功并返回完成。数据在 B 机房的 N4~N5 节点也写入数据成功并返回完成。同一份数据在 A 和 B 机房出现了不一致的情况。</p>
<blockquote>
<p>比如想象 ZK，当一个节点宕机，系统将其踢出集群，然后其他一般以上的节点写入成功即可。是不是 ZK 就满足了 CAP 呢。其实这里有一个误区，系统将其踢出集群，有一个隐含条件，系统引入了一个调度者——一个踢出失败节点的调度者。如果调度者和 ZK 节点出现网络分区时，整个系统是不可用的。</p>
</blockquote>
<h2 id=常见场景>常见场景</h2>
<p>在网络分区无法避免的情况下，一致性和可用性必须二选一。而在没有发生网络故障时，即分布式系统正常运行时，一致性和可用性是可以被同时满足的。但是，对于大多数互联网应用来说，因为规模比较大，部署节点分散，网络故障是常态，可用性是必须要保证的，所有只有舍弃一致性来保证服务的 AP。但是对于一些金融相关的行业来说，有很多场景需要保证一致性，这种情况下通常会考虑 CA 和 CP 模型，CA 模型在网络故障时完全不可用，CP 模型具备部分可用性。</p>
<p><strong>CA without P</strong>：关注一致性和可用性，需要非常严格的全体一致性协议，比如“2PC”。 CA 系统不能容忍网络错误或节点错误，一旦出现这样的问题，整个系统就会拒绝写请求，因为它并不知道对面的那个节点是否挂掉了，还是只是网络问题。唯一安全的方式就是把自己设置为<strong>只读</strong>。</p>
<p><strong>CP without A</strong>：关注一致性和分区容忍性。关注的是系统中大多数节点的一致性协议，比如 Paxos 算法。这样的系统只需要保证大多数节点数据一致，而少数节点会在没有同步到最新数据版本时变为不可用状态，从而提供<strong>部分可用性</strong>。</p>
<p><strong>AP without C</strong>：关注可用性和分区容忍性。因此，这样的系统不能达成一致性，需要给出数据冲突，给出数据冲突就需要维护数据版本。Dynamo 就是这样的系统。</p>
<p>对于分布式系统分区容忍性是天然具备的要求，否则一旦出现网络分区，系统就拒绝所有写入只允许可读，这对大部分的场景是不可接收的，因此，在设计分布式系统时，更多的情况下是选举 CP 还是 AP，要么选择强一致性弱可用性，要么选择高可用性容忍弱一致性。</p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-6a5395c7553310a95d78b1d98ba7a178>4 - BASE</h1>
<p>弱一致性BASE：</p>
<p>多数情况下，其实我们也并非一定要求强一致性，部分业务可以容忍一定程度的延迟一致，所以为了兼顾效率，发展出来了最终一致性理论BASE，BASE是指基本可用（Basically Available）、软状态（ Soft State）、最终一致性（ Eventual Consistency）</p>
<ul>
<li>基本可用(Basically Available)：基本可用是指分布式系统在出现故障的时候，允许损失部分可用性，即保证核心可用。</li>
<li>软状态(Soft State)：软状态是指允许系统存在中间状态，而该中间状态不会影响系统整体可用性。分布式存储中一般一份数据至少会有三个副本，允许不同节点间副本同步的延时就是软状态的体现。</li>
<li>最终一致性(Eventual Consistency)：最终一致性是指系统中的所有数据副本经过一定时间后，最终能够达到一致的状态。弱一致性和强一致性相反，最终一致性是弱一致性的一种特殊情况。</li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-ddde0499c9ea9d037fe2d5463046b0f8>5 - CALM</h1>
<p>分布式架构的核心就在一致性的实现和妥协，那么如何设计一套算法来保证不同节点之间的通信和数据达到无限趋向一致性，就非常重要了。保证不同节点在充满不确定性网络环境下能达成相同副本的一致性是非常困难的，业界对该课题也做了大量的研究。</p>
<p>首先我们要了解一致性的大前提原则(CALM):</p>
<p>CALM原则的全称是 Consistency and Logical Monotonicity ，主要描述的是分布式系统中单调逻辑与一致性的关系，它的内容如下，参考consistency as logical monotonicity：</p>
<ul>
<li>在分布式系统中，单调的逻辑都能保证 “最终一致性”，这个过程中不需要依赖中心节点的调度</li>
<li>任意分布式系统，如果所有的非单调逻辑都有中心节点调度，那么这个分布式系统就可以实现最终“一致性”</li>
</ul>
<h2 id=单调逻辑和非单调逻辑>单调逻辑和非单调逻辑</h2>
<p>如果一个结论是由单调逻辑根据一系列信息推理出来的，那么这个结论就会一直有效，即使后来又获得了新的信息。简单来说，就是后来的推论永远不会影响到之前推论的有效性。</p>
<p>反之，如果新的信息会导致之前的推论无效，那么这样的逻辑就是非单调逻辑。</p>
<h2 id=一个逻辑非单调的例子>一个逻辑非单调的例子</h2>
<p>如果T是鸟，那么我们认为T可以飞，这样的逻辑可以表述为：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>Bird(T) -&gt; Fly(T)
</code></pre></div><p>现在有一只鸟 Tweet，那么 <code>Bird(Tweet)</code> 是成立的，那么是否就有 Fly(Tweet) 呢？根据现在已知的条件，我们可以很容易做出结论：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>Bird(Tweet) -&gt; Fly(Tweet)
</code></pre></div><p>这样的逻辑看起似乎没什么问题，但是随着我们知识的增长，我们会发现一些特例：</p>
<ul>
<li>如果Tweet是企鹅或者鸡，那么Tweet不能飞</li>
<li>如果Tweet的翅膀严重受伤了，那么Tweet不能飞</li>
</ul>
<p>如果Tweet是上面条件中之一，那么 Fly(Tweet) 的结论就会失效。这样的逻辑就是非单调逻辑。</p>
<p>非单调逻辑的一个特点就是没有考虑全部的知识。</p>
<h2 id=一个逻辑单调的例子>一个逻辑单调的例子</h2>
<p>例如数学上常见的逆否命题推论：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>如果 P -&gt; Q
那么 -Q -&gt; -P
</code></pre></div><p>这个推论无论P和Q的内容是什么都是成立的。单调逻辑的特点就是已经考虑了全部的情况。</p>
<h2 id=非单调逻辑>非单调逻辑</h2>
<p>现实世界中总是有各种特例情况，我们通常无法再下结论之前考虑到所有的情况。所以大部分逻辑通常都是非单调逻辑（基于假设），非单调逻辑一般有5种类型的假设，例如：已知船通常可以用来渡河，现在有一艘船A，船A可以渡河吗？</p>
<ul>
<li>主观认知逻辑(subjective autoepistemic)：船A可以渡河，因为我没有得到任何船A无法渡河的信息。</li>
<li>原型逻辑(prototical)：船A可以渡河，因为已知：船通常可以渡河</li>
<li>最低风险逻辑（No-Risk）: 如果假设船A不能渡河，并且如果我的假设错误，那么我就浪费这一次渡河的机会（这是无法接受的），所以假设船A可以渡河。（最低风险是依据自己的利益来假设的，也可用类似的逻辑最终推导出“船A不能渡河”，具体的结果依据自身的利益来决定）</li>
<li>最优猜测逻辑(Best-Guest)：首先我需要渡河，但是除了船A以外我不知道还有没有其他船，所以假设船A可以渡河</li>
<li>概率逻辑(Probabilistic): 超过80%的船可以渡河，所以假设船A也可以渡河</li>
</ul>
<h2 id=reference>Reference</h2>
<ul>
<li><a href=https://lfwen.site/2018/05/13/calm/>CALM：一致性与逻辑单调</a></li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-85b030129557bd100a1ee0d311e2a99b>6 - Gossip</h1>
<p>Gossip是一种去中心化、容错并保证最终一致性的协议。</p>
<h2 id=背景>背景</h2>
<p>Gossip是为了解决分布式遇到的问题而设计的。由于服务和数据分布在不同的机器上，节点之间的每次交互都伴随着网络延迟、网络故障等的性能问题。可见，分布式系统会比单机系统遇到更多的难题。</p>
<p>如CAP理论 所描述的，CAP三个因素在分布式的条件下只能满足两个。对于分布式系统来说，分区容忍性是基本要求。因为分布式系统的设计初衷就是利用集群多集的能力去处理单机无法解决的问题。分区容忍性（可扩展性）通过通过scale up和scale out实现的，也就是通过升级硬件或者增加机器来提升分布式系统的性能。这么说，可扩展性和可用性是相关联的。可扩展性好的系统，其可用性一般会比较高。所以分布式系统的所有问题基本都是在一致性和可用性之间进行协调和平衡。在工程实践中的经验如下：</p>
<p>一般来说，交易系统类的业务对一致性的要求比较高，一般会采用ACID模型来保证数据的强一致性，所以其可用性和扩展性就比较差。而其他大多数业务系统一般不需要保证强一致性，只要最终一致就可以了，它们一般采用BASE模型，用最终一致性的思想来设计分布式系统，从而使得系统可以达到很高的可用性和扩展性。</p>
<p>一致性可以通过信息在分布式环境下分发来保证，而分发的方式和速度则决定一致性的程度。从客户端的角度来讲：一致性包含三种状态：强一致性、弱一致性、最终一致性（弱一致性的特例）。在下图的一致性光谱中我们可以看出，弱一致性性是异步冗余，读写操作的响应更加快；而强一致性一般都是同步冗余的，所以伴随着性能的下降。</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190225001445.png style=display:block;width:50% alt=NAME align=center> </div>
<p>而最终一致性还有其他变种：因果一致性（有逻辑关系的操作能读到更新值）、读你所写一致性（Read-your-writes Consistency，A用户操作只保证自己的后续操作能读到更新值）、会话一致性（保证整个会话期间的读写一致性）、单调一致性（单用户的操作顺序一致）。</p>
<h2 id=swim最终一致性>SWIM：最终一致性</h2>
<p>前面提到Gossip解决的问题就是在分布式环境下信息高效分发的问题，这个问题的解决决定着系统的一致性程度。而Gossip协议是基于一种叫做SWIM的协议（ S calable W eakly-consistent I nfection-style Process Group M embership Protocol）。SWIM是一种无中心的分布式协议，各个节点之间通过 P2P 实现信息交流同步各节点状态的方法。看名字也知道这是一种弱一致性的实现。</p>
<p>SWIM协议给每个进程组成员在本地维护一个成员表，记录该组存活的进程。该协议通过失效检测器（Failure Detector）和传播组件（Dissemination Component）来完成工作。</p>
<p>SWIM的失效检测器会检测失效的节点并将失效节点的更新信息发送给传播组件。SWIM的传播组件通过多播（multicast）的形式将失效信息传播给组内的其他成员。</p>
<p>协议的可扩展性体现在：新成员的加入和退出也以同样的方式进行多播通信。而在基本的时间周期内进行失效检测能够保证在限定的时间范围内完成完备性检查，即每个失效的进程都能最终被检测到（最终一致性）。通过多播方式传输协议消的问题在于效率不好也不可靠，通过在ping和ack消息中捎带成员更新信息能够降低丢包率和减少传输时延。这种传播方式被称为可传导的方式（Infection-style）。</p>
<h2 id=gossip办公室八卦>Gossip：办公室八卦</h2>
<p>我们的办公室八卦一般都是从一次交谈开始，只要一个人八卦一下，在有限的时间内办公室的的人都会知道该八卦的信息，这种方式也与病毒传播类似。因此 Gossip也有“病毒感染算法”、“谣言传播算法”之称。</p>
<p>Gossip来源于流行病学的研究（括号里就是Gossip协议）：</p>
<ol>
<li>在总数为n+1的人群中，被感染（infected）的人数初始化为1，并向周围传播。（一个节点状态发生变化，并向临近节点发送更新信息）</li>
</ol>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190225001213.png style=display:block;width:50% alt=NAME align=center> </div>
<ol start=2>
<li>在每个周期内总有未被感染（uninfected）的人转变成被感染的人，方式为每个被感染的人随机感染b个人。（对于节点状态变化的信息随机发送给b个节点，图例中的b值为2）</li>
</ol>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190225001545.png style=display:block;width:50% alt=NAME align=center> </div>
<ol start=3>
<li>经过足够的时间，所有的人都会被感染。（随着时间推移，信息能够传达到所有的节点，下一节会进行简单的证明）</li>
</ol>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190225001627.png style=display:block;width:50% alt=NAME align=center> </div>
<p>可以看到，协议的核心内容就是节点通过将信息随机发送到b个节点来完成本次信息的传播，其涉及到周期性、配对、交互模式。Gossip的交互模式分为两种：Anti-entropy和Rumor mongering。</p>
<ul>
<li>Anti-entropy：每个节点周期性地随机选择其他节点，然后通过相互交换自己的所有数据来消除两者之间的差异。</li>
<li>Rumor mongering：当一个节点有来新信息后，该节点变成活跃状态，并周期性地联系其他节点向其发送新信息。</li>
</ul>
<p>每个节点维护一个自己的信息表 &lt;key, (value, version)> ，即属性的值以及版本号；和一个记录其他节点的信息表 &lt;node, &lt;key, (value, version)&#187; 。每个节点和系统中的某个节点相互配对成为peer。而节点的信息交换方式主要有3种。</p>
<ul>
<li>Push：拥有状态新信息的节点随机选择联系节点并想起发送自己得到信息。</li>
<li>Pull：发起信息交换的节点随机选择联系节点并从对方获取信息。</li>
<li>Push-Pull混合模式：发起信息交换的节点向选择的节点发送信息。</li>
</ul>
<p>上述Gossip为什么能够完成状态的同步呢？我们对其做一个简单的分析。</p>
<h2 id=analysis收敛性证明>Analysis：收敛性证明</h2>
<p>我们以上一节的Push模式Gossip协议进行分析。</p>
<p>在n+1个节点的系统中，每个节点每次随机向其他b个节点进行信息通信，即传播速率：β=bn。</p>
<p>在连续时间过程中，x的变化速率dxdt=−βxy</p>
<p>而总时间为 t=clog(n)</p>
<p>那么当c和b都是独立于n的很小的数值时。Gossip协议能够保证：</p>
<ul>
<li>低延迟：在clog(n)内完成一次信息的更新。虽然不是常数级别的，但是其对数级别增长率在程序世界里是实践上可取的。</li>
<li>可靠性：n+1−1ncb−2</li>
<li>轻量级：每个节点不会发送超过cblog(n)条信息。</li>
</ul>
<p>这样我们不仅证明了Gossip的可靠性，并可以保证其在分布式系统应用的高可用性。注意的是，即使有的节点因宕机而重启或者有新节点加入，但经过一段时间后，这些节点的状态也会与其他节点达成一致。也就是说，Gossip天然具有分布式容错的优点。</p>
<h2 id=application应用>Application：应用</h2>
<p>除了改善SWIM协议中的多播方式，Gossip还在很多地方有应用：</p>
<ul>
<li>数据库复制：基于Gossip实现分布数据管理的一般思路是：在一个节点实现数据更新，通过Gossip算法将更新传播导其他节点。</li>
<li>聚合计算：在无中心的系统中，没有中心节点存储全局信息。通过Gossip应用导分布环境下的聚合计算中来保证系统的发送消息的容错。</li>
</ul>
<p>总之，Gossip简单、高效，同时具有很好的可扩展性和鲁棒性，非常适合大规模、动态、资源受限的网络环境。</p>
<p>但Gossip的缺点也很明显，冗余通信会对网路带宽、CPU资源造成很大的负载，而这些负载又受限于通信频率，该频率又影响着算法收敛的速度。</p>
<h2 id=算法样例-脑裂问题>算法样例-脑裂问题</h2>
<p>Cassandra内部有一个Gossiper，每隔一秒运行一次（在Gossiper.java的start方法中），按照以下规则向其他节点发送同步消息：</p>
<ul>
<li>随机取一个当前活着的节点，并向它发送同步请求</li>
<li>向随机一台不可达的机器发送同步请求</li>
<li>如果第一步中所选择的节点不是seed，或者当前活着的节点数少于seed数，则向随意一台seed发送同步请求</li>
</ul>
<p>如果没有这个判断，考虑这样一种场景，有4台机器，{A, B, C, D}，并且配置了它们都是seed，如果它们同时启动，可能会出现这样的情形：</p>
<ol>
<li>A节点起来，发现没有活着的节点，走到第三步，和任意一个种子同步，假设选择了B</li>
<li>B节点和A完成同步，则认为A活着，它将和A同步，由于A是种子，B将不再和其他种子同步</li>
<li>C节点起来，发现没有活着的节点，同样走到第三步，和任意一个种子同步，假设这次选择了D</li>
<li>C节点和D完成同步，认为D活着，则它将和D同步，由于D也是种子，所以C也不再和其他种子同步</li>
</ol>
<p>这时就形成了两个孤岛，A和B互相同步，C和D之间互相同步，但是{A,B}和{C,D}之间将不再互相同步，它们也就不知道对方的存在了。</p>
<p>加入第二个判断后，A和B同步完，发现只有一个节点活着，但是seed有4个，这时会再和任意一个seed通信，从而打破这个孤岛。</p>
<h2 id=reference>Reference</h2>
<ul>
<li><a href=https://www.cnblogs.com/wangzhongqiu/p/8866377.html>Gossip 协议</a></li>
<li><a href=http://www.10tiao.com/html/536/201901/2650716387/1.html>Gossip 协议</a></li>
<li><a href=https://leokongwq.github.io/2018/01/01/gossip-intro.html>Gossip 算法介绍</a></li>
<li><a href=https://flopezluis.github.io/gossip-simulator/>Gossip 可视化</a></li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-fe4f4b1b211faeadd32b75cc984329ce>7 - CRDT</h1>
<p>我们了解到分布式一些规律原则之后，就要着手考虑如何来实现解决方案，一致性算法的前提是数据结构，或者说一切算法的根基都是数据结构，设计良好的数据结构加上精妙的算法可以高效的解决现实的问题。经过前人不断的探索，我们得知分布式系统被广泛采用的数据结构CRDT。</p>
<p>参考《谈谈CRDT》,A comprehensive study of Convergent and Commutative Replicated Data Types</p>
<ul>
<li>基于状态(state-based)：即将各个节点之间的CRDT数据直接进行合并，所有节点都能最终合并到同一个状态，数据合并的顺序不会影响到最终的结果。</li>
<li>基于操作(operation-based)：将每一次对数据的操作通知给其他节点。只要节点知道了对数据的所有操作（收到操作的顺序可以是任意的），就能合并到同一个状态。</li>
</ul>
<hr>
<h2 id=什么是-crdt>什么是 CRDT</h2>
<p>CRDT 是 Conflict-Free Replicated Data Type 的缩写，即<strong>无冲突的可复制数据类型</strong>。</p>
<p>它用于解决分布式系统的最终一致性问题，即，在分布式系统中，应用采用什么样的数据结构来保证最终一致性？而 CRDT 是目前理论界给出的答案，相关论文为 <a href=http://hal.upmc.fr/file/index/docid/555588/filename/techreport.pdf>A comprehensive study of Convergent and Commutative Replicated Data Types</a>。</p>
<h2 id=一致性的难题>一致性的难题</h2>
<p>构建一个分布式系统并不难，而难的是构建一个与单机系统的正确性一样的分布式系统，即 <a href=https://en.wikipedia.org/wiki/CAP_theorem>CAP 定理</a>。</p>
<p>CAP 定理告诉我们，在构建分布式系统时，Consistency(一致性)、Availability(可用性)、Partition tolerance(分区容错性)，三者只能同时选取两项。</p>
<p>其中，分区容错性是任何生产环境下的分布式系统所必须的，因此，只有在 C、A 之间做出取舍：</p>
<ul>
<li>选择一致性：构建一个强一致性系统，比如符合 ACID 特性的数据库系统。</li>
<li>选择可用性：构建一个最终一致性系统，比如 NoSQL 系统。</li>
</ul>
<p>选择一致性时数据一旦落地就是一致的，但是可用性不能实时保证，比如系统有时忙于一致性处理，无法对外提供服务。</p>
<p>选择可用性时则时刻都能保证可用，但是各个节点在同一时刻所持有的数据可能并不一致，但经过一段时间后，数据在各节点间会达到一致状态。</p>
<p><strong>因此，现在的分布式系统总是会偏向于选择 AP，以提供一个无单点故障、总是可用且更高吞吐的系统。</strong></p>
<h2 id=使用那些信息能够达到最终一致>使用那些信息能够达到最终一致</h2>
<p>在实际应用中，我们需要考虑多种数据类型的应用和场景，设计一个能够保证最终一致性的数据结构会变得很复杂。</p>
<p>而 CRDT 就是这样一些适用于不同场景的、可以保持最终一致性的数据结构的统称。围绕 CRDT 理论，则涵盖了：</p>
<ul>
<li>它们应该具有怎样的基本表现形式</li>
<li>满足一些什么样的条件才可以保持最终一致性，毕竟不能每次都穷举所有情况</li>
<li>不断寻找一些通用的、有大量应用场景的 CRDT，并努力提高其空间、时间效率</li>
</ul>
<p>前面提到的 CRDT 相关论文总结了目前为止人们在 CRDT 这件事情上的认识程度，简要总结如下：</p>
<ul>
<li>定义了 CRDT</li>
<li>列举了 CRDT 的两种基本形式：
<ul>
<li>基于状态的 CRDT：存储最终值</li>
<li>基于操作的 CRDT：存储操作记录</li>
</ul>
</li>
<li>界定了 CRDT 能够满足最终一致性的边界条件。比如，设计一个 CRDT，只需要验证它是否满足这些边界条件，即可知道它是否能够保持最终一致性</li>
<li>界定了两类 CRDT 在系统中应用时，需要的信息交换的边界条件。即回答怎样才能叫做”收集到足够多的信息“</li>
<li>枚举了当前已知的 CRDT，包括计数器(counter)、寄存器(register)、集合(set)、图(graph)等几个种类</li>
<li>在现实中应用如何应用 CRDT，尤其是如何回收存储空间的问题</li>
</ul>
<h2 id=如何在实际系统中应用>如何在实际系统中应用</h2>
<p>最终一致性分布式框架 RiakCore 的应用方式：</p>
<ul>
<li>抛弃自己缩写的数据结构，实现 CRDT，或者使用已有的 CRDT Library</li>
<li>参考 CRDT 的一致性可判断条件(即”收集到足够多的信息“)，在需要判断最终一致性时收集它们</li>
<li>抛弃自己所写的一致性判断算法，实现 CRDT 的一致性合并算法，或者使用已有的 CRDT Library</li>
</ul>
<blockquote>
<p><a href=https://github.com/basho/riak>Riak</a> 是一个由 Erlang 编写的分布式、去中心化的数据存储系统，<a href=https://github.com/basho/riak_core>Riak Core</a> 定义了其数据分发和扩展的形式，可以被认为是一个用于构建分布式、可扩展、高容错应用的工具集。</p>
</blockquote>
<h2 id=谁应该使用>谁应该使用？</h2>
<p>所有力求追踪一致性的系统，都应该使用 CRDT。如果一个最终一致性的分布式系统还有没有使用 CRDT，要么是其所使用的数据结构已经实现了 CRDT 的一种或几种，虽然可能很粗糙，要么是这个系统在最终一致性上的保证存在问题。</p>
<h2 id=总结>总结</h2>
<p>CRDT 并未给用户层面带来影响，但是从管理员、开发者的角度来看，CRDT 给了我们基于逻辑来判断分布式系统能否保证最终一致性的能力。</p>
<h2 id=reference>Reference</h2>
<ul>
<li><a href=http://blog.chinaunix.net/uid-608135-id-4730055.html>Eventual Consistency：谈谈 CRDT</a></li>
<li><a href=http://liyu1981.github.io/what-is-CRDT/>http://liyu1981.github.io/what-is-CRDT/</a></li>
<li><a href=http://christophermeiklejohn.com/crdt/2014/07/22/readings-in-crdts.html>http://christophermeiklejohn.com/crdt/2014/07/22/readings-in-crdts.html</a></li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-739b5ff30013dd87c474793ad2e1437d>8 - 2PC</h1>
<p>2PC 是一种非常有影响力的协议，<strong>用于确保访问多个分区或分片中的数据的事务的原子性和持久性</strong>。它无处不在 – 无论是在旧的“古老的”分布式系统、数据库系统和文件系统，如Oracle，IBM DB2，PostgreSQL 和 Microsoft TxF（支持事务的 NTFS）还是在较年轻的“千禧”系统如 MariaDB、TokuDB、VoltDB、Cloud Spanner、Apache Flink、Apache Kafka 和 Azure SQL 数据库。如果您的系统支持跨分片/分区/数据库的 ACID 事务，那么它很可能会在后台运行 2PC（或其某些变体）。有时它甚至出现在“前台” – 旧版本的 MongoDB 要求用户在应用程序代码中为多文档事务实现 2PC。</p>
<p>在这篇文章中，我们将首先介绍一下 2PC：它是如何工作的以及它解决了什么问题。然后，我们将展示 2PC 的一些主要问题以及现代系统如何试图解决它。不幸的是，这些尝试的解决方案也带来了一些其他问题。在文章最后，我将说明下一代分布式系统应该避免使用 2PC，以及如何实现这一点。</p>
<h2 id=概述>概述</h2>
<p>2PC 有很多变种，但基本协议的工作原理如下。</p>
<p>基本假设：一个事务相关的工作已经划分给存储该事务数据的分片节点。我们将在每个分片中执行的工作，称为节点“参与者”的工作。当事务准备好“提交”时，每个参与者都能够独立于彼此完成事务相应的职责。2PC 协议由单个独立的、可协调的节点发起（可能是参与者之一）。</p>
<p>2PC 协议的基本流程如下图所示。（协议从图的顶部开始，然后向下进行。）</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190221193731.png style=display:block;width:80% alt=NAME align=center> </div>
<p>阶段1：协调者询问每个参与者，是否已成功完成其对该事务的职责，并达到可以提交的状态。每个参与者都回答“同意”或“反对”。</p>
<p>阶段2：协调者统计所有回应，如果每个参与者都回答“同意”，那么就提交事务，否则就中止事务。协调者向每个具有提交最终决策权力的参与者发送消息，并接收参与者的确认消息。</p>
<p>此机制确保事务的原子性属性：整个事务将反映在系统的最终状态中，或者不反映在系统的最终状态中。即使只有一个参与者没有提交，那么整个事务将会被中止。换句话说：每个参与者对事务都有“否决权”。</p>
<p>它还确保了事务的持久性。每个参与者确保在阶段1响应“同意”之前，已将所有事务持久地写入存储。这使协调者对事务做出最终决定时，无需担心参与者在投票“同意”之后写入失败。在这篇文章中，当使用术语“持久写入”时，我们有目的地模糊化了两个区别 – 本地临时性存储，或是分布式的写入到多个分片以“持久化”。</p>
<p>除了持久地写入事务相关的数据之外，协议本身还需要额外的写入，在处理消息之前必须使其持久化。例如，一名参与者在第一阶段投票“同意”之前拥有否决权，但在此之后，它不能改变其投票结果。但如果它在投票“同意”后立即崩溃怎么办？ 当它恢复时，它可能不知道它投了“同意”，仍然认为它拥有否决权，并继续流程并中止事务。为了防止这种情况，它必须在“同意”投票发给协调者之前，持久化相关投票结果。（除了这个例子，在标准的 2PC 流程中，还有另外两种消息需要发送前持久化操作。）</p>
<h2 id=问题>问题</h2>
<p>2PC 存在两个主要问题。第一个是众所周知的，并在所有讲述 2PC 的教科书中都进行了讨论。第二个不太知名，但仍然是一个大的问题。</p>
<h3 id=阻塞问题>阻塞问题</h3>
<p>众所周知的问题被称为“阻塞（block）问题”。当每个参与者都投了“同意”，但协调者在将最终决定的消息未能发送给至少一参与者之前就挂了，就会出现这种情况。问题的原因是，通过投票“同意”，每个参与者已经取消了否决事务的权力。但是，协调者仍有绝对权力来决定事务的最终状态。如果协调者在向至少一名参与者发送最终决定的消息之前挂了，那么参与者就无法做出最终决定 – 他们不能中止，因为协调者可能会在挂掉之前决定提交，并且他们无法提交，因为协调者可能决定在失败之前中止。因此，他们必须等待—等到协调者恢复—以便得到最终决定。与此同时，他们无法处理与停滞冲突的事务，因为该事务的写入的最终结果尚未确定。</p>
<p>阻塞问题有两种解决方案。方案一是修改核心协议以消除阻塞问题。不幸的是，这些修改降低了性能 – 通常通过添加额外的一轮通信来实现 – 因此很少在实践中使用。</p>
<p>方案二是保持协议不变，但降低协调者失败从而引发阻塞的可能性 – 例如，通过在副本共识协议上运行 2PC 并确保协议的重要状态被复制。不幸的是，这些解决方案再一次降低了性能，因为协议要求这些副本共识轮次按顺序进行，因此它们可能会给协议增加显著的延迟。</p>
<h3 id=拥堵问题>拥堵问题</h3>
<p>鲜为人知的问题是我称之为“拥堵(cloggage)问题”。在处理事务之后进行 2PC，必然增加事务的等待时间，它等于运行协议所花费的时间。延迟的增加对于许多系统来说已经是一个问题，但更大的问题是，工作节点必须到第二阶段中期才知道事务的最终结果。在他们得到最终结果之前，他们必须为可能中止事务的可能性做好准备，因此在事务得到确认之前，他们通常会暂停其他有冲突的事务进行。这些阻塞的事务同样会进一步阻止其他事务运行，依此类推，直到 2PC 完成，所有被阻止的事务才可以恢复。这些拥堵问题进一步增加了事务平均延迟，并且降低了整体的事务吞吐量。</p>
<h3 id=结论>结论</h3>
<p>总结我们上面讨论的问题：2PC 在四个方面污染了系统架构：<strong>延迟</strong> （协议的时间加上冲突事务的停顿时间），<strong>吞吐量</strong>（因为它碰到冲突的事务会停顿），<strong>可扩展性</strong> （系统越大，事务更需要多分区的支持，并且必须付出 2PC 的吞吐量和延迟成本以及<strong>可用性</strong>（前面提到的阻塞问题）。</p>
<p>没有人喜欢 2PC，但几十年来，人们都认为它是一种必要的妥协。</p>
<h2 id=解决方案>解决方案</h2>
<p>三十多年来，业界一直在分布式系统中使用两阶段提交。我们已经意识到引入 2PC 会带来性能、可伸缩性和可用性问题，但在没有更好的替代方案之前，仍需要选择使用它。</p>
<p>真相就是，如果有更好的方案，2PC 就没必要存在了。为了实现这一目标，无论是在学术界（如SIGMOD 2016论文）和工业界都在进行尝试。通常的做法是避免分布式事务，例如通过在提交事务之前将数据重新分片，使得事务不再是分布式事务。不幸的是，这种重新分片的做法降低了系统的性能。</p>
<p>我倡导对分布式系统架构进行更深层次的优化。我坚持认为系统可以使用更简单和高效的提交协议，在保证 ACID 的同时，能够处理分布式事务。</p>
<p>一切问题的根源来自一个存在数十年的假设：事务可能随时以任何理由中止。即使我在相同的初始系统状态下运行相同的事务，在下午 2:00 它可能可以成功提交，但在 3:00 时却会提交失败。</p>
<p>为什么需要该假设？大多数架构师认为有以下几个原因。首先，节点可能在任何时候失败，包括在事务处理过程中。系统故障恢复过程中，由于无法获取故障前的内存状态，因此也无法恢复事务失败之前的现场。因此系统需要中止故障出现时所有相关事务。由于任何时候都可能发生故障，这意味着事务可能随时中止。</p>
<p>其次，大多数并发控制协议都需要能够随时中止事务。乐观协议在处理事务后执行“验证”，如果验证失败，则中止事务。悲观协议通常使用锁来防止并发异常，这种锁的使用可能会导致死锁，然后又需要通过中止（至少）事务的方法来解决死锁问题。由于可能随时出现死锁，因此事务需要保留随时中止的能力。</p>
<p>如果来重新审视两阶段提交协议，您将看到随时中止事务的可能性，是 2PC 协议中复杂和延迟的主要原因。参与者不能轻易地告诉其他方是否同意提交，因为他可能在此之后（在事务提交前）出现故障，然后在故障恢复期间中止此事务。因此，他们必须等到事务结束（当所有重要状态都已经持久化）并且严格按照两个阶段进行处理：在第一阶段，每个参与者公开放弃其控制以中止事务，然后才能进入第二阶段，作出最终决定并进行广播。</p>
<p>在我看来，我们需要从参与者中移除否决权，并且以系统无法在执行期间随时中止事务的假设来进行架构设计。只接受以业务逻辑需要来否决事务的情况。如果在给定数据库当前状态下，理论上可以提交事务情况下，无论发生何种类型的故障，该事务都必须可以提交。此外也不接受由于其他并发运行导致的竞争条件而不能最终提交或中止事务。</p>
<p>消除随意中止事务的灵活性听起来很难。我们将很快讨论如何实现这一目标。但首先让我们观察在不能随意中止事务的情况下，提交协议会如何变化。</p>
<h2 id=当事务不能随意中止时提交协议是什么样的>当事务不能随意中止时，提交协议是什么样的</h2>
<p>我们来看两个例子。</p>
<p>在第一个例子中，假设存储变量 X 的节点需要执行一个任务：将 X 的值更改为 42。假设在 X 上没有定义完整性约束或触发器（这可能会阻止系统将 X 设为 42）。在这种情况下，该参与方永远没有中止事务的权力。无论发生什么，该参与方必须将 X 更改为42，如果修改过程中出现系统故障，则必须在故障恢复后将 X 设成 42。由于参与方没有随意中止事务的能力，因此在提交协议期间，不需要检测参与方是否可以提交。</p>
<p>在第二个例子中，假设存储变量 Y 和 Z 值的节点接收到两个事务任务：从前一个 Y 值中减去 1 并将 Z 设置为 Y 的新值。此外，假设 Y 上存在完整性约束，表明 Y 永远不会低于 0（例如它代表零售应用程序中的库存）。因此，此参与方必须运行以下代码：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>IF (Y &gt; 0)
	Subtract 1 from Y
ELSE
	ABORT the transaction
Z = Y
</code></pre></div><p>因为应用程序的逻辑需要这样做，所以必须赋予参与者中止事务的权力。但是这种权力是受限的。只有当 Y 的初始值为 0 时，才能中止该事务，否则必须提交。因此，参与方不必等到完成事务之后才知道它是否需要提交。相反：一旦它完成了事务中第一行代码的执行，它就已经知道了最终需要提交还是中止。这意味着相比于 2PC 而言，提交协议将能够更早地启动。</p>
<p>现在让我们将这两个例子组合成一个例子，其中一个事务由两个参与者执行 – 其中一个参与者正在完成第一个例子中描述的工作，另一个参与者正在完成第二个例子中描述的工作。由于我们保证原子性，第一个参与者不能简单地将 X 设置为 42，相反，它自己的工作依赖于 Y 的值。实际上，第一个参与者的事务代码变为：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>temp = Do_Remote_Read(Y)
if (temp &gt; 0)
    X = 42
</code></pre></div><p>请注意，如果第一个参与者的代码如上的话，那么另一个参与者的代码可以简化为：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-fallback data-lang=fallback>IF (Y &gt; 0)
	Subtract 1 from Y
	Z = Y
</code></pre></div><p>通过以这种方式编写事务代码，两个参与方都删除了显式中止逻辑。相反，两个参与方都有 if 语句来检查是否会导致原始事务中止的约束。如果原始事务中止，两个参与方最终都无所作为。否则，两个参与方都会根据事务逻辑更改其本地状态。</p>
<p>此时需要注意的一点是，<strong>在上面的代码中完全消除了对提交协议的需求</strong>。除了应用程序代码在给定数据状态下定义的条件逻辑以外的任何原因，系统都不允许中止事务。并且所有参与者都在这个相同的条件上调整他们的动作，这样他们就可以独立地决定，在由于当前系统状态而无法完成事务的情况下“什么也不做”。因此，已经消除了事务中止的所有可能性，并且在事务处理结束时不需要任何类型的分布式协议来做出关于事务组合的最终决定。2PC 的所有问题都已消除。因为没有协调者，所以也没有阻塞（block）问题。因为所有必要的检查都与事务处理时候完成，而非在事务完成之后检查，所以没有拥堵（cloggage）问题。</p>
<p>此外，只要不允许系统因应用程序逻辑之外的任何原因而中止事务，总是可以像上面那样重写任何事务以替换代码中的中止逻辑，即 if 语句有条件地检查中止条件。此外，可以在重写应用程序代码的情况下实现此目的。（有关如何执行此操作的详细信息超出了本文的范围，但可以高屋建瓴地总结为：当一个节点执行了导致中止的条件逻辑时，它可以设置特殊的标记，其他节点可以在远程读取这些标记。）</p>
<p>实质上：在事务处理系统中有两种类型中止：（1）由数据状态引起的中止和（2）由系统本身引起的中止（例如故障或死锁）。如上所述，类别（1）总是可以根据数据的条件逻辑来编写。因此，如果您可以消除类别（2）中止，则可以消除提交协议。</p>
<p>所以现在，我们所要做的就是解释如何消除类别（2）中止。</p>
<h2 id=消除系统本身中止>消除系统本身中止</h2>
<p>我花了将近十年的时间来设计没有系统引发中止的系统。此类系统的示例是 Calvin，CalvinFS，Orthrus，PVW 以及惰性处理事务系统。这一特性的推动力来自于— Calvin —因为它是一个确定性数据库系统。确定性数据库保证在给定一组定义的输入请求的情况下，数据库中只有一个可能的最终数据状态。因此，如果将相同的输入发送到系统的两份不同的副本，两份副本将独立地处理该输入，并将最终达到一致的结果。</p>
<p>系统本身中止，例如系统故障或并发控制竞态条件，从根本上说是不确定性事件。一个副本很可能碰见系统调用失败或进入竞态条件，而另一个副本则不会。如果允许这些非确定性事件导致事务中止，则一个副本会中止事务而另一个副本将提交事务 – 这是对确定性的违背。因此，我们必须以系统故障和竞态条件不能导致事务中止的方式设计 Calvin。对于并发控制，Calvin 使用了避免死锁技术的悲观锁定，该技术确保系统永远不会陷入由于死锁导致的事务中止的状况。面对系统故障，Calvin 无法从中断的位置重启事务（因为在故障期间失去了内存状态）。尽管如此，通过从相同的原始输入重新启动事务，它依然能够完成该事务的处理而不必中止它。</p>
<p>这些解决方案（包括防止死锁以及故障重启恢复事务），都不局限于在确定性数据库系统中使用。在非确定性系统中，如果失败期间，丢失的事务状态被其他非故障节点侦测到，那么事务重启变得略微棘手。但是也有一些简单的方法来解决这个问题，但这些方法已经超出了本文讨论的范围。实际上，我上面提到的其他系统都是非确定性系统。一旦我们意识到消除系统本身故障所带来的威力，我们就将设计植入到 Calvin 之后构建的每个系统中 – 甚至是非确定性系统。</p>
<h2 id=结论-1>结论</h2>
<p>系统架构师继续在分区系统中使用 2PC 的好处微乎其微。我认为，忽略系统本身中止以及状态写入故障是更好的前进方法。确定性数据库系统（如 Calvin 或 FaunaDB）总是会规避系统本身中止，因此通常可避免 2PC。但是这种优势仅发挥在确定性数据库是一个巨大的浪费。从非确定性系统中消除系统本身引起的中止并不困难。最近的项目表明，甚至可以在不使用悲观并发控制技术的系统中消除系统引起的中止。例如，我们上面链接的 PVW 和惰性事务处理系统都使用多版本并发控制（MVCC）的变体。FaunaDB 使用乐观并发控制的变体。</p>
<p>在我看来，几乎没有理由坚持过时的系统性中止假设，当系统在单台机器上运行时，这种假设是合理的。然而，很多现代系统已经扩展到到多台可以故障隔离的机器上。维持该假设就需要成本高昂类似 2PC 的协调和提交协议。2PC 的性能问题一直是非 ACID 系统兴起的主要推动力，这些系统放弃了强一致性保证，以达到更好的可扩展性、可用性和性能。2PC 太慢了！它增加了所有事务的延迟，不仅仅是协议本身的时间占用，还阻止了访问相同数据的其他事务的并发执行。此外，2PC 还限制了可伸缩性（通过降低并发性）和可用性（我们上面讨论的阻塞问题）。前进的道路已经很明确：我们需要在设计系统时重新审视过时的假设，并对两阶段提交说“再见”！</p>
<h2 id=reference>Reference</h2>
<ul>
<li><a href=http://dbmsmusings.blogspot.com/2019/01/its-time-to-move-on-from-two-phase.html>It’s Time to Move on from Two Phase Commit</a></li>
<li><a href=http://matt33.com/2018/07/08/distribute-system-consistency-protocol/>分布式系统的一致性协议之 2PC 和 3PC</a></li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-62dc23672a681227dd62dfb84e0f21b1>9 - 3PC</h1>
<p>三阶段提交协议最关键要解决的问题就是 Coordinator 和参与者同时挂掉导致数据不一致的问题，所以 3PC 在 2PC 的基础上又添加了一个阶段：CanCommit、PreCommit、DoCommit。</p>
<h2 id=过程>过程</h2>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190224210148.png style=display:block;width:50% alt=NAME align=center> </div>
<h3 id=1cancommit>1：CanCommit</h3>
<ol>
<li>事务轮序：Coordinator 向各个参与者发送 CanCommit 请求，询问是否可以执行事务提交操作，并开始等待所有参与者的响应。</li>
<li>参与者向 Coordinator 反馈询问的响应：参与者收到 CanCommit 请求之后，正常情况下，如果自身认为可以顺利执行事务，那么会返回 Yes 响应并进入预备专题，否则返回 No。</li>
</ol>
<h3 id=2precommit>2：PreCommit</h3>
<p><strong>执行事务预提交</strong>：如果 Coordinator 接收到各个参与者的反馈都是 Yes，那么执行事务预提交：</p>
<ol>
<li>发送预提交请求：Coordinator 向各参与者发送 PreCommit 请求，进入 prepared 阶段。</li>
<li>事务预提交：参与者接收到 PreCommit 请求之后，会执行事务操作，并将 Undo 和 Redo 信息记录到事务日志中。</li>
<li>参与者向 Coordinator 反馈事务执行的响应：如果各参与者都成功执行了事务操作，那么反馈给 Coordinator ACK 响应，同时开始等待最终指令：提交 commit 或终止 abort，结束流程。</li>
</ol>
<p><strong>中断事务</strong>：如果任何一个参与者向 Coordinator 反馈了 No 响应，或者在等待超时后，Coordinator 无法接收到所有参与者的反馈，那么就会中断事务。</p>
<ol>
<li>发送中断请求：Coordinator 向所有参与者发送 abort 请求。</li>
<li>中断事务：无论收到来自 Coordinator 的 abort 请求，还是等待超时，参与者都中断事务。</li>
</ol>
<h3 id=3docommit>3：DoCommit</h3>
<p><strong>执行提交</strong>：</p>
<ol>
<li>发送提交事务：假设 Coordinator 正常工作，接收到了所有参与者的 ACK，那么他将从预提交阶段进入提交阶段，并向所有参与者发送 DoCommit 请求。</li>
<li>事务提交：参与者收到 DoCommit 请求之后，正式提交事务，并在完成事务提交之后释放占用的资源。</li>
<li>反馈事务提交结果：参与者完成事务提交之后，向 Coordinator 发送 ACK。</li>
<li>完成事务：Coordinator 接收到所有参与者的 ACK，完成事务。</li>
</ol>
<p><strong>中断事务</strong>：假设 Coordinator 正常工作，并且有任一参与者反馈 No，或者在等待超时后无法接受到所有参与者的反馈，都会中断事务：</p>
<ol>
<li>发送中断请求：Coordinator 向所有参与者节点发送 abort 请求。</li>
<li>事务回滚：参与者收到 abort 请求之后，利用 undo 日志执行事务回滚，并在完成事务回滚后释放占用资源。</li>
<li>返回事务回滚结果：参与者在完成事务回滚之后，向 Coordinator 发送 ACK。</li>
<li>中断事务：Coordinator 接收到所有参与者反馈的 ACK，中断事务。</li>
</ol>
<h2 id=分析>分析</h2>
<p>3PC 虽然解决了 Coordinator 与参与者均异常情况下导致数据不一致的问题，3PC 依然带来了其他问题。比如，网络分区问题，在 PreCommit 消息发出后突然两个机房断开网络，这时 Coordinator 所在机会会 abort，另外剩余的参与者的机房则会 commit。</p>
<p>而且由于 3PC 的设计过于复杂，在解决 2PC 问题的时候也引入了新的问题，因此实际应用并不广泛。</p>
<h2 id=reference>Reference</h2>
<ul>
<li><a href=http://matt33.com/2018/07/08/distribute-system-consistency-protocol/>分布式系统的一致性协议之 2PC 和 3PC</a></li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-b7cdad8f05e730f72e061037f7dc3c57>10 - Paxos</h1>
<p>分布式系统除了能提升整个系统的性能外还有一个重要的特性就是提高系统的可靠性，可靠性指的是当分布式系统中一台或N台机器宕掉后都不会导致系统不可用，分布式系统是 “state machine replication” 的，每个节点都可能是其他节点的快照，这是保证分布式系统高可靠性的关键，而存在多个复制节点就会存在数据不一致的问题，这时一致性就成了分布式系统的核心；在分布式系统中必须保证：</p>
<p><strong>加入在分布式系统中初始时各个节点的数据是一致的，每个节点都顺序执行系列操作，然后每个节点最终的数据还是一致的。</strong></p>
<p><strong>一致性算法</strong>：用于保证在分布式系统中每个节点都顺序执行相同的操作序列，在每个指令上执行<strong>一致性算法</strong>就能保证各个节点最终的数据是一致的。</p>
<p>Paxos 就是用于解决一致性问题的算法。有多个节点就会存在节点之间的通信问题，有两种通信模型：共享内存、消息传递。Paxos 是基于消息传递的通信模型。</p>
<h2 id=概述>概述</h2>
<blockquote>
<p>Paxos 用于解决分布式系统中的一致性问题。在一个 Paxos 过程只批准一个 Value，只有被 Prepare 的 Value 且被多数 Acceptor 接受才能被批准，被批准的 Value 只能被 Learner。</p>
</blockquote>
<p>流程简述：</p>
<ol>
<li>有一个 Client、三个 Proposer、三个 Acceptor、一个 Leaner；</li>
<li>Client 向 Prepare 提交一个 Data 请求入库，Proposer 接收到 Client 请求后生成一个序列号 1 向三个 Acceptor(或最少两个)发送序号 1 请求提案。</li>
<li>假如三个 Acceptor 收到 Proposer 申请提交的序号 1 提案，且三个 Acceptor 都是初次接收到该提案，这时向 Proposer 回复 Promise 允许提交的提案。</li>
<li>Proposer 收到三个 Acceptor(满足过半原则)的 Promise 回复后接着向三个 Acceptor 正式提交提案(序号 1，value 为 data)。</li>
<li>三个 Acceptor 都受到该提案，请求期间没有收到其他请求，Acceptor 则接受提案，回复 Proposer 已接受提案，然后向 Learner 提交提案。</li>
<li>Proposer 收到回复后给 Client 成功处理请求。</li>
<li>Learner 收到提案后开始学习提案(存储 Data)。</li>
</ol>
<p>角色划分：</p>
<ul>
<li>Proposer：提议者</li>
<li>Acceptor：决策者</li>
<li>Learner：提案学习者</li>
</ul>
<p>阶段划分：</p>
<ol>
<li>准备阶段
<ol>
<li>Proposer 向超过半数(n/2+1)的 Acceptor 发起 Prepare 消息(提案编号)。</li>
<li>如果 Prepare 符合协议规则，Acceptor 回复 Promise 消息，否则拒绝。</li>
</ol>
</li>
<li>决议阶段(投票阶段)
<ol>
<li>如果超过半数 Acceptor 回复 Promise，Proposer 向 Acceptor 发送 Accept 消息。</li>
<li>Acceptor 检查 Accept 消息是否符合规则，消息符合规则则批准 Accept 请求。</li>
</ol>
</li>
</ol>
<h2 id=详解>详解</h2>
<h3 id=paxos-保证>Paxos 保证</h3>
<ul>
<li>只有提出的议案才能被选中，没有议案提出就不会被选中。</li>
<li>多个被提出的议案中只有一个议案会被选中。</li>
<li>议案被选中后 Learner 就可以开始学习该议案。</li>
</ul>
<h3 id=约束条件>约束条件</h3>
<p><strong>P1-Acceptor 必须接受它接收到的第一个议案</strong>。有约束就会出现一个问题：当多个议案被多个 Proposer 同时提出，这时每个 Acceptor 都接收到了它们各自的第一个议案，此时无法选择最终议案。所以就需要另一个约束 P2。</p>
<p><strong>P2-一个议案被选中需要过半的 Acceptor 接受</strong>。</p>
<p>假设 A 为整个 Acceptor 集合；B 为超过 A 一半的 Acceptor 集合，B 为 A 的子集；C 也是超过 A 半数的 Acceptor 集合，C 也是 A 的子集。由此可知，任意两个超过半数的子集中必定有一个相同的成员 Acceptor。</p>
<p>此说明了一个 Acceptor 可以接受不止一个议案，此时需要一个编号来标识每个议案，议案的编号格式为：(编号，Value)。编号为不可重复且全序。</p>
<p>因为一个 Paxos 过程只能批准一个 Value，这时退出了约束 P3。</p>
<p><strong>P3-当编号为 K0、Value 为 V0 的议案(K0,V0)被过半的 Acceptor 接受后，今后(同一个 Paxos 或称一个 Round 中)，所有比 K0 更高编号且被 Acceptor 接受的议案，其 Value 必须为 V0</strong>。</p>
<p>因为每个 Proposer 都可以提出多个议案，每个议案最初都有一个不同的 Value，所有要满足 P3 就又要退出一个新的约束 P4。</p>
<p><strong>P4-只有 Acceptor 没有接受过议案，Proposer 才能采用自己的 Value，否则 Proposer 的 Value 议案为 Acceptor 中编号最大的 Proposer Value</strong>。</p>
<h3 id=paxos-流程>Paxos 流程</h3>
<p>这里具体例子来说明 Paxos 的整个具体流程： 假如有 Server1、Server2、Server3 这样三台服务器，我们要从中选出 leader，这时候 Paxos 派上用场了。整个选举的结构图如下：</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190224215847.png style=display:block;width:50% alt=NAME align=center> </div>
<h4 id=1-准备阶段>1-准备阶段</h4>
<ol>
<li>每个 Server 都向 Proposer 发消息称自己想成为 leader，Server1 往 Proposer1 发、Server2 往 Proposer2 发、Server3 往 Proposer3 发；</li>
<li>现在每个 Proposer 都接收到了 Server1 发来的消息但时间不一样， Proposer2 先接收到了，然后是 Proposer1，接着才是 Proposer3；
<ol>
<li>Proposer2 首先接收到消息所以他从系统中取得一个编号 1，Proposer2 向 Acceptor2 和 Acceptor3 发送一条，编号为 1 的消息；</li>
<li>接着 Proposer1 也接收到了 Server1 发来的消息，取得一个编号 2，Proposer1 向 Acceptor1 和 Acceptor2 发送一条，编号为 2 的消息；</li>
<li>最后 Proposer3 也接收到了 Server3 发来的消息，取得一个编号 3，Proposer3 向 Acceptor2 和 Acceptor3 发送一条，编号为 3 的消息；</li>
</ol>
</li>
<li>这时 Proposer1 发送的消息先到达 Acceptor1 和 Acceptor2，这两个都没有接收过请求所以接受了请求返回 (2,null) 给 Proposer1，并承诺不接受编号小于 2 的请求；</li>
<li>此时 Proposer2 发送的消息到达 Acceptor2 和 Acceptor3，Acceprot3 没有接收过请求则返回 (1,null) 给 Proposer2，并承诺不接受编号小于 1 的请求，但这时 Acceptor2 已经接受过 Proposer1 的请求并承诺不接受编号小于的 2 的请求了，所以 Acceptor2 拒绝 Proposer2 的请求；</li>
<li>最后 Proposer3 发送的消息到达 Acceptor2 和 Acceptor3， Acceptor2 接受过提议，但此时编号为 3 大于 Acceptor2 的承诺 2 与 Accetpor3 的承诺 1，所以接受提议返回 (3,null);</li>
<li>Proposer2 没收到过半的回复所以重新取得编号 4，并发送给 Acceptor2 和 Acceptor3，然后A cceptor2 和 Acceptor3 都收到消息，此时编号 4 大于 Acceptor2 与 Accetpor3 的承诺 3，所以接受提议返回 (4,null)；</li>
</ol>
<h4 id=2-决议阶段>2-决议阶段</h4>
<ol>
<li>Proposer3 收到过半的返回，并且返回的 Value 为 null，所以Proposer3 提交了 (3,server3) 的议案；</li>
<li>Proposer1 收到过半返回，返回的 Value 为 null，所以 Proposer1提交了 (2,server1) 的议案；</li>
<li>Proposer2 收到过半返回，返回的 Value 为 null，所以 Proposer2 提交了 (4,server2) 的议案；</li>
<li>Acceptor1、Acceptor2 接收到 Proposer1 的提案 (2,server1) 请求，Acceptor2 承诺编号大于 4 所以拒绝了通过，Acceptor1 通过了请求；</li>
<li>Proposer2 的提案 (4,server2) 发送到了Acceptor2、Acceptor3，提案编号为 4 所以 Acceptor2、Acceptor3 都通过了提案请求；</li>
<li>Acceptor2、Acceptor3 接收到 Proposer3 的提案 (3,server3) 请求，Acceptor2、Acceptor3 承诺编号大于 4 所以拒绝了提案；</li>
<li>此时过半的 Acceptor 都接受了 Proposer2 的提案 (4,server2)，Larner 感知到了提案的通过，Larner 学习提案，server2 成为 Leader；</li>
</ol>
<p>一个 Paxos 过程只会产生一个议案所以至此这个流程结束，选举结果 Server2 为 Leader。</p>
<h2 id=reference>Reference</h2>
<ul>
<li><a href=https://github.com/oldratlee/translations/blob/master/paxos-made-simple/README.rst>Paxos Made Simple</a></li>
<li><a href=https://github.com/oldratlee/translations/blob/master/paxoslease/README.rst>PaxosLease：实现租约的无盘Paxos算法</a></li>
<li><a href=http://www.solinx.co/archives/403>Paxos 过程</a></li>
<li><a href=http://codemacro.com/2014/10/15/explain-poxos/>Paxos 图解</a></li>
<li><a href=https://lfwen.site/2016/12/25/paxos-algorithm/>Paxos 详解</a></li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-2a687026a4d99f00caadb04ffa89c608>11 - ZAB</h1>
<h2 id=背景>背景</h2>
<p>Zookeeper 使用了一种称为 Zab（Zookeeper Atomic Broadcast）的协议作为其一致性复制的核心，据其作者说这是一种新发算法，其特点是充分考虑了 Yahoo 的具体情况：高吞吐量、低延迟、健壮、简单，但不过分要求其扩展性。</p>
<p>Zookeeper 的实现是有 Client、Server 构成，Server 端提供了一个一致性复制、存储服务，Client 端会提供一些具体的语义，比如分布式锁、选举算法、分布式互斥等。从存储内容来说，Server 端更多的是存储一些数据的状态，而非数据内容本身，因此 Zookeeper 可以作为一个小文件系统使用。数据状态的存储量相对不大，完全可以全部加载到内存中，从而极大地消除了通信延迟。</p>
<p>Server 可以 Crash 后重启，考虑到容错性，Server 必须“记住”之前的数据状态，因此数据需要持久化，但吞吐量很高时，磁盘的 IO 便成为系统瓶颈，其解决办法是使用缓存，把随机写变为连续写。</p>
<p>考虑到 Zookeeper 主要操作数据的状态，为了保证状态的一致性， Zookeeper 提出了两个安全属性（Safety Property）：</p>
<ul>
<li>全序(total-order)，如果消息 A 在消息 B 之前发送，则所有 Server 应该看到相同顺序的结果。</li>
<li>因果关系(causal-order)，如果消息 A 在消息 B 之前发生(A 导致了 B)，并被一起发送，则 A 始终在 B 之前执行。</li>
</ul>
<p>为了保证上述两个安全属性，Zookeeper 使用了 TCP 协议和 Leader 机制。通过使用 TCP 协议保证了消息的全序特性（先发先到），通过 Leader 机制解决了因果顺序问题：先到 Leader 的先执行。因为有了 Leader，Zookeeper 的架构就变为：Master-Slave 模式，但在该模式中Master（Leader）会 Crash，因此，Zookeeper 引入了 Leader 选举算法，以保证系统的健壮性。归纳起来 Zookeeper 整个工作分两个阶段：</p>
<ol>
<li>Atomic Broadcast</li>
<li>Leader 选举</li>
</ol>
<h2 id=atomic-broadcast>Atomic Broadcast</h2>
<p>同一时刻存在一个 Leader 节点，其他节点称为 Follower。如果是更新请求，如果客户端连接到 Leader 节点，则由 Leader 节点执行其请求；如果连接到 Follower 节点，则需转发到 Leader 节点执行。但对于读请求，Client 可以直接从 Follower 节点读取数据，如果需要读取到最新数据，则需要从 Leader 节点读取，Zookeeper 设计的读写比例是 2：1。</p>
<p>Leader 通过一个简化版的 2PC 模式向其他 Follower 发送请求，但与 2PC 有两个不同之处：</p>
<ul>
<li>因为只有一个 Leader，Leader 提交到 Follower 的请求一定会被接受(没有其他 Leader 干扰)。</li>
<li>不需要所有 Follower 都响应成功，只要多数响应即可。</li>
</ul>
<p>通俗的说，如果有 2f+1 个节点，允许 f 个节点失败。因为任何两个过半数集必要一个交集，当 Leader 切换时，通过这些交集节点可以获得当前系统的最新状态。如果没有一个过半数集存在(存活节点少于 f+1)则算法过程结束。</p>
<p>但又一个特例：如果 ABC 三个节点，A 是 Leader，如果 B 宕机，则 AC 能够正常工作，因为 A 是 Leader，AC 还能构成过半数集；如果 A 宕机则无法继续工作，因为用于 Leader 选举的过半数集无法构成。</p>
<h2 id=leader-election>Leader Election</h2>
<p>Leader 选举主要是依赖 Paxos 算法，具体算法过程请参考其他博文，这里仅考虑 Leader 选举带来的一些问题。</p>
<p>Leader 选举遇到的最大问题是，”新老交互“的问题，新 Leader 是否要继续老 Leader 的状态。这里要按老 Leader Crash 的时机点分几种情况：</p>
<ol>
<li>老 Leader 在 COMMIT 前 Crash（已经提交到本地）。</li>
<li>老 Leader 在 COMMIT 后 Crash，但有部分 Follower 接收到了Commit请求。</li>
</ol>
<p>第一种情况，这些数据只有老 Leader 自己知道，当老 Leader 重启后，需要与新 Leader 同步并把这些数据从本地删除，以维持状态一致。</p>
<p>第二种情况，新 Leader 应该能通过一个多数派获得老 Leader 提交的最新数据。老 Leader 重启后，可能还会认为自己是 Leader，可能会继续发送未完成的请求，从而因为两个 Leader 同时存在导致算法过程失败，解决办法是把 Leader 信息加入每条消息的 id 中，Zookeeper 中称为 zxid，zxid 为一 64 位数字，高 32 位为 leader 信息又称为 epoch，每次 leader 转换时递增；低 32 位为消息编号，Leader 转换时应该从 0 重新开始编号。通过 zxid，Follower 能很容易发现请求是否来自老 Leader，从而拒绝老 Leader 的请求。</p>
<p>因为在老 Leader 中存在着数据删除（情况1），因此 Zookeeper 的数据存储要支持补偿操作，这也就需要像数据库一样记录 log。</p>
<h2 id=zab-与-paxos>ZAB 与 Paxos</h2>
<p>Zab 的作者认为 Zab 与 Paxos 并不相同，只所以没有采用 Paxos 是因为 Paxos 保证不了全序顺序：</p>
<blockquote>
<p>Because multiple leaders can propose a value for a given instance two problems arise.
First, proposals can conflict. Paxos uses ballots to detect and resolve conflicting proposals.
Second, it is not enough to know that a given instance number has been committed, processes must also be able to figure out which value has been committed.</p>
</blockquote>
<p>Paxos 算法的确是不关心请求之间的逻辑顺序，而只考虑数据之间的全序，但很少有人直接使用 Paxos 算法，都会经过一定的简化、优化。</p>
<p>一般 Paxos 都会有几种简化形式，其中之一便是，在存在 Leader 的情况下，可以简化为 1 个阶段（Leader Election）。仅有一个阶段的场景需要有一个健壮的 Leader，因此工作重点就变为 Leader 选举，在考虑到 Learner 的过程，还需要一个”学习“的阶段，通过这种方式，Paxos 可简化为两个阶段：</p>
<ol>
<li>Leader Election</li>
<li>Learner Learn</li>
</ol>
<p>如果再考虑多数派要 Learn 成功，这其实就是 Zab 协议。Paxos 算法着重是强调了选举过程的控制，对决议学习考虑的不多，Zab 恰好对此进行了补充。</p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-26ac83d880caeb19690c75cfe250a72e>12 - Raft</h1>
<h2 id=基本概念>基本概念</h2>
<h3 id=复制状态机>复制状态机</h3>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190224225452.png style=display:block;width:50% alt=NAME align=center> </div>
<ul>
<li>复制状态机通过日志复制来实现：
<ul>
<li>日志：每台机器保存一份日志，日志来自客户端的请求，包含一系列命令。</li>
<li>状态机：状态机会按序执行这些命令。</li>
<li>一致性模型：分布式环境中，保证多机的日志是一致的，这样回放到状态机中得到的状态就是一致的。</li>
</ul>
</li>
<li>一致性算法用于一致性模型，一般有以下特性：
<ul>
<li>Safety：在非拜占庭问题下(网络延时、网络分区、丢包、重复包、包乱序)，结果是正确的。</li>
<li>Availability：在半数以上机器能正常工作时，服务可用。</li>
<li>Timing-unindepentent：不依赖于时钟来保持日志一致性，错误的时钟以及极端的消息延时最多会造成可用性问题。</li>
</ul>
</li>
</ul>
<blockquote>
<p>实际的实现中，建议状态机的每个命令曹邹都是幂等的，这样更易于保证一致性。</p>
</blockquote>
<h3 id=服务器状态>服务器状态</h3>
<p>每台服务器一定会处于三种状态：</p>
<ul>
<li>领导者</li>
<li>候选者</li>
<li>追随者</li>
</ul>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190224230043.png style=display:block;width:50% alt=NAME align=center> </div>
<ul>
<li>追随者只响应其他服务器的请求。如果追随者没有收到任何消息，它会成为一个候选者并开始一次选举。</li>
<li>收到大多数服务器投票的候选者将称为新的领导者。</li>
<li>领导者在宕机之前会一致保持领导者的状态。</li>
</ul>
<h3 id=任期>任期</h3>
<p>Raft 算法将事件划分为任意不同长度的任期(Term)。任期用连续的数字来表示。每个任期的开始都是一次选举(election)，一个或多个候选者会试图称为领导者。如果一个候选者赢得了选举，他就会在该任期的剩余时间内担任领导者。在某些情况下，选票会被瓜分，有可能没有选出领导者。这时将开始另一个任期，并且立刻开始下一次选举。Raft 算法保证在指定的任期内只有一个领导者。</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190224230534.png style=display:block;width:50% alt=NAME align=center> </div>
<h3 id=rpc>RPC</h3>
<p>Raft 算法中服务器节点之间通过 RPC 通信，并且基本的一致性算法只需要两种类型的 RPC。请求投票 RPC 由候选者在选举期间发起，然后附加条目 RPC 由领导者发起，用来复制日志或提供一种心跳机制。为了服务器之间传输快照增加了第三种 RPC。当服务器没有及时收到 RPC 的响应时会尝试重试，并且它们能够并行的发起 RPC 来获得最佳性能。RPC 有三种：</p>
<ol>
<li>RequestVote RPC：候选者在选举期间发起。</li>
<li>AppendEntries RPC：领导者发起的一种心跳机制，或用于日志复制。</li>
<li>InstallSnapshot RPC：领导者使用该 RPC 来发送快照给过于落后的追随者。</li>
</ol>
<p>超时设置：</p>
<ol>
<li>BroadcastTime：领导者的心跳超时。</li>
<li>ElectionTimeout：追随者设置的候选超时时间。</li>
<li>MTBF：指的是单个服务器发生故障的间隔时间的平均值。</li>
</ol>
<p>BroadcastTime &lt; ElectionTimeout &lt; MTBT 原则：</p>
<ol>
<li>BroadcastTime 应该比 ElectionTimeout 小一个数量级，为的是使领导者能够持续发送心跳信息来避免追随者开始发起选举。</li>
<li>ElectionTimeout 应该比 MTBT 小几个数量级，为的是使系统稳定运行。</li>
</ol>
<p>一般 BroadcastTime 大约为 0.5 毫秒到 20 毫秒，ElectionTimeout 一般在 10ms 到 500ms 之间。大多数服务器的 MTBF 都在几个月甚至更长。</p>
<h2 id=选举>选举</h2>
<p><strong>触发条件</strong>：</p>
<ol>
<li>一般情况下，追随者接收到领导者的心跳时，会重置 ElectionTimeout，不会触发。</li>
<li>领导者故障，追随者的 ElectionTimeout 发生超时，会转换为候选者，触发选举。</li>
</ol>
<p><strong>候选操作过程</strong>：</p>
<p>追随者自增当前任期，转换为候选者，对自己投票，并发起 RequestVote RPC，等待以下三种情况发生：</p>
<ul>
<li>获得超过半数服务器的投票，赢得选举，称为领导者。</li>
<li>另一台服务器赢得选举，并接收到对应的心跳，称为追随者。</li>
<li>选举超时，没有任何一台服务器赢得选举，自增当前任期，重新发起选举。</li>
</ul>
<p><strong>注意事项</strong>：</p>
<ul>
<li>服务器在一个任期内，最多只能给一个候选者投票，采用先到先服务原则。</li>
<li>候选者等待投票期间，可能会接收到来自其他声明称为领导者的 AppendEntries RPC。如果该领导人的任期(RCP 的内容)比当当前候选者的任期要大，则当前候选者认为该领导者合法，并转换称为追随者；如果 RPC 中的任期小于当前任期，则后选择拒绝此次 RPC，继续保持候选者状态。</li>
<li>候选者既没有赢得选举也没有输得选举：如果很多追随者在同一时刻都称为了候选者，选票会被分散，可能没有候选者获得较多的投票。当这种情况发生时，每一个候选者都会超时，并且通过自增任期号和发起另一轮 RequestVote RPC 来开始新的选举。然而，如果没有其他手段来分配选票的话，这种情况可能会无限制的重复下去。所以 Raft 使用的随机方式来设置选举超时时间(150~300ms)来避免这种情况的发生。</li>
</ul>
<p><strong>问题探讨</strong>：</p>
<ul>
<li>候选者已经给自己投票了，一个候选者在一个任期内只会给一个人投票。</li>
<li>也有可能算法本身设定候选者就拒绝所有其他服务器的请求。</li>
</ul>
<h2 id=日志复制>日志复制</h2>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190224232428.png style=display:block;width:50% alt=NAME align=center> </div>
<p><strong>接收命令过程</strong>：</p>
<ol>
<li>领导者接受客户端请求。</li>
<li>领导者将命令追加到日志。</li>
<li>发送 AppendEntries RPC 请求到追随者。</li>
<li>领导者收到大多数追随者的确认后，领导者 Commit 日志，将日志在状态机中回放，并返回结果给客户端。</li>
</ol>
<p><strong>提交过程</strong>：</p>
<ol>
<li>在下一个心跳阶段，领导者再次发送 AppendEntries RPC 给追随者，日志已经 Commit 完成。</li>
<li>追随者收到 Commit 结果之后，将日志在状态机中回放。</li>
</ol>
<h2 id=安全性>安全性</h2>
<p>到目前为止描述的机制并不能充分的保证每一个状态机会按照相同的顺序执行相同的指令，例如：一个跟随者可能会进入不可用状态同时领导人已经提交了若干的日志条目，然后这个跟随者可能会被选举为领导人并且覆盖这些日志条目；因此，不同的状态机可能会执行不同的指令序列。</p>
<h3 id=1-领导者追加日志>1. 领导者追加日志</h3>
<p>领导者永远不会覆盖已经存在的日志条目；日志永远只有一个流向：从领导者到追随者；</p>
<h3 id=2-选举限制投票阻止没有全部日志条目的服务器赢得选举>2. 选举限制：投票阻止没有全部日志条目的服务器赢得选举</h3>
<p>如果投票者的日志比候选人的新，拒绝投票请求；这意味着要赢得选举，候选者的日志至少和大多数服务器的日志一样新，那么它一定包含全部的已经提交的日志条目。</p>
<h3 id=3-永远不提交任期之前的日志条目只提交任期内的日志条目>3. 永远不提交任期之前的日志条目（只提交任期内的日志条目）</h3>
<p>在Raft算法中，当一个日志被安全的复制到绝大多数的机器上面，即AppendEntries RPC在绝大多数服务器正确返回了，那么这个日志就是被提交了，然后领导者会更新 “commit index”。</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190224232951.png style=display:block;width:50% alt=NAME align=center> </div>
<p>如果允许提交任期之前的日志条目，那么在步骤 c 中，我们就会把之前任期为 2 的日志提交到其他服务器中去，并造成了大多数机器存在了日志为 2 的情况。所以造成了 d 中 S5 中任期为 3 的日志条目会覆盖掉已经提交的日志的情况。</p>
<p>Raft 从来不会通过计算复制的数目来提交之前人气的日志条目。只有领导人当前任期的日志条目才能通过计算数目来进行提交。一旦当前任期的日志条目以这种方式被提交，那么由于日志匹配原则（Log Matching Property），之前的日志条目也都会被间接的提交。</p>
<p>论文中的这段话比较难理解，更加直观的说：由于 Raft 不会提交任期之前的日志条目，那么就不会从 b 过渡到 c 的情况，只能从 b 发生 S5 宕机的情况下直接过渡到 e，这样就产生的更新的任期，这样 S5 就没有机会被选为领导者了。</p>
<h3 id=4-候选者和追随者崩溃>4. 候选者和追随者崩溃</h3>
<p>候选者和追随者崩溃的情况处理要简单的多。如果这类角色崩溃了，那么后续发送给他们的 RequestVote 和 AppendEntries 的所有 RPC 都会失败，Raft 算法中处理这类失败就是简单的无限重试的方式。如果这些服务器重新可用，那么这些 RPC 就会成功返回。如果一个服务器完成了一个 RPC，但是在响应 Leader 前崩溃了，那么当他再次可用的时候还会收到相同的 RPC 请求，此时接收服务器负责检查，比如如果收到了已经包含该条日志的 RPC 请求，可以直接忽略这个请求，确保对系统是无害的。</p>
<h2 id=集群成员变更>集群成员变更</h2>
<p>集群成员的变更和成员的宕机与重启不同，因为前者会修改成员个数进而影响到领导者的选取和决议过程，因为在分布式系统这对于 majority 这个集群中成员大多数的概念是极为重要的。</p>
<p>简单的做法是，运维人员将系统临时下线，修改配置，重新上线。但是这种做法存在两个缺点：</p>
<ul>
<li>更改时集群不可用</li>
<li>认为操作失误风险</li>
</ul>
<h3 id=直接从一种配置转到新的配置是十分不安全的>直接从一种配置转到新的配置是十分不安全的</h3>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190224233534.png style=display:block;width:50% alt=NAME align=center> </div>
<p>因为各个机器可能在任何的时候进行转换。在这个例子中，集群配额从 3 台机器变成了 5 台。不幸的是，存在这样的一个时间点，两个不同的领导人在同一个任期里都可以被选举成功。一个是通过旧的配置，一个通过新的配置。</p>
<h3 id=两阶段方法保证安全性>两阶段方法保证安全性</h3>
<p>为了保证安全性，配置更改必须使用两阶段方法。在 Raft 中，集群先切换到一个过渡的配置，我们称之为共同一致；一旦共同一致已经被提交了，那么系统就切换到新的配置上。共同一致是老配置和新配置的结合。</p>
<p>共同一致允许独立的服务器在不影响安全性的前提下，在不同的时间进行配置转换过程。此外，共同一致可以让集群在配置转换的过程人依然响应服务器请求。</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190224233844.png style=display:block;width:50% alt=NAME align=center> </div>
<p>一个领导人接收到一个改变配置从 C-old 到 C-new 的请求，他会为了共同一致存储配置（图中的 C-old,new），以前面描述的日志条目和副本的形式。一旦一个服务器将新的配置日志条目增加到它的日志中，他就会用这个配置来做出未来所有的决定。领导人完全特性保证了只有拥有 C-old,new 日志条目的服务器才有可能被选举为领导人。当 C-old,new 日志条目被提交以后，领导人在使用相同的策略提交 C-new，如下图所示，C-old 和 C-new 没有任何机会同时做出单方面的决定，这就保证了安全性。</p>
<p>上图是一个配置切换的时间线。虚线表示已经被创建但是还没有被提交的条目，实线表示最后被提交的日志条目。领导人首先创建了 C-old,new 的配置条目在自己的日志中，并提交到 C-old,new 中（C-old,new 的大多数和 C-new 的大多数）。然后他创建 C-new 条目并提交到 C-new 中的大多数。这样就不存在 C-new 和 C-old 可以同时做出决定的时间点。</p>
<h2 id=日志压缩>日志压缩</h2>
<p>日志会随着系统的不断运行会无限制的增长，这会给存储带来压力，几乎所有的分布式系统(Chubby、ZooKeeper)都采用快照的方式进行日志压缩，做完快照之后快照会在稳定持久存储中保存，而快照之前的日志和快照就可以丢弃掉。</p>
<p>Raft的具体做法如下图所示：</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190224234023.png style=display:block;width:50% alt=NAME align=center> </div>
<p>与 Raft 其它操作 Leader-Based 不同，snapshot 是由各个节点独立生成的。除了日志压缩这一个作用之外，snapshot 还可以用于同步状态：slow-follower 以及 new-server，Raft 使用 InstallSnapshot RPC 完成该过程，不再赘述。</p>
<h2 id=client-交互>Client 交互</h2>
<ul>
<li>Client 只向领导者发送请求；</li>
<li>Client 开始会向追随者发送请求，追随者拒绝 Client 的请求，并重定向到领导者；</li>
<li>Client 请求失败，会超时重新发送请求。</li>
</ul>
<p>Raft 算法要求 Client 的请求线性化，防止请求被多次执行。有两个解决方案：</p>
<ul>
<li>Raft 算法提出要求每个请求有个唯一标识；</li>
<li>Raft 的请求保持幂等性。</li>
</ul>
<h2 id=reference>Reference</h2>
<ul>
<li><a href="http://blog.luoyuanhang.com/2017/02/02/raft-paper-in-zh-CN/?hmsr=toutiao.io&utm_medium=toutiao.io&utm_source=toutiao.io">论文</a></li>
<li>ETCD Raft 库的实现</li>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI3NDIxNTQyOQ==&mid=2247484544&idx=1&sn=7d8e412ecc5aaeb3f9b7cf391bdcf398&chksm=eb1623eadc61aafcefcfbdf36b388a5f96d3009d21641eb6ac67c57317d6c397ddeb58fc7d06#rd">TiKV 源码解析系列 - Raft 的优化</a></li>
<li><a href="https://zhuanlan.zhihu.com/p/33047950?hmsr=toutiao.io&utm_medium=toutiao.io&utm_source=toutiao.io">Elasticell-Multi-Raft实现</a></li>
<li><a href="http://tinylcy.me/2018/Understanding-the-Raft-consensus-algorithm-Two/?hmsr=toutiao.io&utm_medium=toutiao.io&utm_source=toutiao.io">Raft 理解</a></li>
<li><a href=https://juejin.im/entry/59bf3643f265da0655052fba>Raft 一致性算法笔记</a></li>
<li><a href=https://juejin.im/post/5aed9a7551882506a36c659e>Raft 协议理解</a></li>
<li><a href=https://zhuanlan.zhihu.com/p/32052223>Raft 算法详解</a></li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-898151233fb238dfbda40e8b0930717c>13 - 分布式一致性</h1>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20171203151229046633987.png style=display:block;width:50% alt=NAME align=center> </div>
<h2 id=什么是一致性问题>什么是一致性问题</h2>
<p>以银行 ATM 为例，假设 A 的账户内有 200 存款，某一时刻 A 和其朋友 B 同时在不同的两个 ATM 机执行”取款 200“的操作，此时系统便出现了一致性问题，因为无论系统做出何种回应都会导致不一致的问题：</p>
<ul>
<li>系统接受一方的取款请求，拒绝另一方的取款请求：一方会认为系统不可用</li>
<li>系统同时接受两个请求：账户发生透支</li>
<li>系统同时拒绝两个请求：双方均认为系统不可用</li>
</ul>
<h2 id=解决一致性问题的算法>解决一致性问题的算法</h2>
<h3 id=lamport-面包店算法>Lamport 面包店算法</h3>
<p>每个请求先申请到一个独一无二的号码，然后按照号码小者优先的规则进行办理。即在分布式系统中维护一个全局的”排号系统“。</p>
<p>这要求高质量的硬件环境，参考<a href="http://www.xtecher.com/Xfeature/view?aid=3452">谷歌利用GPS和原子钟使数据库全球范围信息同步</a>。</p>
<h3 id=vector-clocks>Vector Clocks</h3>
<p>同样由上面算法的作者 Lamport 提出，算是对上面算法的改进，去除了维护全局排号系统的负担。</p>
<p>该算法通过一系列计数器实现。还是 ATM 的例子，A、B 所用的 ATM 机需要自己维护一个计数器序列，每次操作将这个序列里自己的计数器加一，当 ATM 发送请求到系统时附带上该序列。假设两台 ATM 的计数器一开始都是 0，A 操作后将发送 <code>[{a,1}, {b,0}]</code>，B 操作后将发送 <code>[{a,0}, {b,1}]</code>，可以发现 A 发送的 b 比 B 发送的 b 要小，说明有冲突，此时按照时间顺序谁先到处理谁，后来的拒绝。假如同时到达则按 ATM 机的字母排号选择，即先 A 后 B。</p>
<p>注意，Vector Clocks 仅用来发现冲突，并不包含冲突的解决过程。Riak 和早期的 Cassandra、Dynamo 应用了该算法。但是该算法需要每次请求前先像其他节点获得对方计数器的最新版本，而且要给 Vector Clocks 预留存储空间，造成性能和资源消耗的加剧，因此效果不佳。</p>
<h3 id=选举算法>选举算法</h3>
<p>首先在系统中通过既定的规则选举出一个 Master，其余节点都是 Slave，外来请求均通过 Master 来处理，Slave 仅需从 Master 节点同步数据即可。常见的算法实现比如 <strong>Paxos</strong> 和 <strong>Raft</strong>。</p>
<p>缺点是，当 Master 失效后系统会执行选举过程，这是系统会处于短暂的不可用状态。</p>
<h3 id=quorum-nrw>Quorum NRW</h3>
<p>一种从客户端侧解决一致性问题的投票算法，通过客户端同步操作多个实例来保证一致性，具体冲突解决由客户端实现，其主要数据思想来源于<a href=https://zh.wikipedia.org/wiki/%E9%B4%BF%E5%B7%A2%E5%8E%9F%E7%90%86>鸽巢原理</a>，可以保证同一份数据对象的多份拷贝不会被超过两个访问对象读写。</p>
<p>分布式系统中的每一份数据对象都被赋予一票，每个操作必须要获得最小的读票数(Vr)或者最小的写票数(Vw)，才能进行读写。如果一个系统有 V 票，即一个数据对象有 V 份冗余拷贝，那么最小的读写票数必须满足：</p>
<ul>
<li>Vr + Vw > V</li>
<li>Vw > V/2</li>
</ul>
<p>第一条规则保证了一个数据库不会被同时读写。当一个写操作请求过来的时候，它必须要获得Vw个冗余拷贝的许可。而剩下的数量是V-Vw 不够Vr，因此不能再有读请求过来了。同理，当读请求已经获得了Vr个冗余拷贝的许可时，写请求就无法获得许可了。</p>
<p>第二条规则保证了数据的串行化修改，一份数据的冗余拷贝不可能同时被两个写请求修改。</p>
<p>比如一个拥有 5 节点的系统，该算法可以让写操作写完 3 台即返回，剩下的由系统进行同步；而读操作则至少需要读 3 台，才能保证读到一个最新的数据。</p>
<h3 id=rev-tree>Rev Tree</h3>
<p>类似于 Git 的版本树，对每次操作生成一个 Rev id，将每次操作的 Rev id 都放到上次操作之后形成主分支，当一个拥有不一致的 Rev Tree 的数据想要进行合并时冲突产生，这时会生成一个新的分支，然后两个分支同时工作。默认以最长分支为主分支，其他分支及数据会在一段时间后删除。因此有些场景中并不可行。</p>
<p>CouchDB 中应用了该算法，该算法把冲突的解决交给了时间，活跃度最高的数据被保留下来，适用于没有权威决策要求的去中心化系统。</p>
<h3 id=区块链>区块链</h3>
<p>这是比特币网络中用于记录交易过程生成总账本的算法，类似于上面的 Rev Tree，同时基于安全性需求增加了非对称加密、计算能力验证等逻辑。参考<a href=http://blog.codinglabs.org/articles/bitcoin-mechanism-make-easy.html>比特币的原理及运行机制</a>。</p>
<h3 id=crdt>CRDT</h3>
<p>CRDT 值能够避免冲突的可复制数据结构，力图从数据结构上避免冲突，同时这类数据结构的合并过程都会满足 <a href=https://lostechies.com/jimmybogard/2013/06/06/acid-2-0-in-action/>ACID 2.0</a>：</p>
<ul>
<li>结合律：<code>f(a,f(b,c)) = f(f(a,b),c)</code></li>
<li>交换律：<code>f(a,b) = f(b,a)</code></li>
<li>幂等性：<code>f(f(x))=f(x)</code></li>
</ul>
<h2 id=reference>Reference</h2>
<ul>
<li><a href=http://covertness.me/2015/11/08/%E5%88%86%E5%B8%83%E5%BC%8F%E7%B3%BB%E7%BB%9F%E7%9A%84%E4%B8%80%E8%87%B4%E6%80%A7%E9%97%AE%E9%A2%98/>分布式的一致性问题</a></li>
<li><a href="https://weibo.com/ttarticle/p/show?id=2309403965965003062676">保证分布式系统数据一致性的6种方案</a></li>
<li><a href=http://www.jianshu.com/p/1156151e20c8>分布式一致性：案例、模式</a></li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-0abcc623d68d4f0a690005a87e3bea4d>14 - 分布式事务</h1>
<h3 id=什么是事务>什么是事务</h3>
<p>将多个不同的命令组装到一起的过程。</p>
<p>核心：锁与并发</p>
<p>称为事务为了更易理解。</p>
<p>性能较低。</p>
<p>容易理解的模型性能都不好，性能好的模型(锁的粒度小，增加了编程难度)都不易理解。</p>
<p>追求平衡。</p>
<p>事务要保证的问题就是一致性。</p>
<p>ACID保证事务完整性、原子性。什么是ACID？</p>
<p>建索引、读一行数据、插入一行并建索引、删除整张表&mldr;.每个操作都是事务。</p>
<ul>
<li>two phase lock(2PL)：两阶段锁，读(加锁) - 操作 - 提交(解锁)</li>
</ul>
<h3 id=事务单元>事务单元</h3>
<p>多个事务单元关联时，每个事务单元都不会看到数据的中间状态。</p>
<p>事务单元之间的 happen-before 关系：</p>
<ul>
<li>读写</li>
<li>写读</li>
<li>读读</li>
<li>写写</li>
</ul>
<blockquote>
<p>《事务处理》</p>
</blockquote>
<p>如何满足事务关联的同时更快完成(速度)？如何保证上面四种操作的逻辑顺序(正确性)？</p>
<ul>
<li>排队各种操作：串行序列化、不需要冲突控制，但是慢，</li>
<li>针对同一个单元的访问进行访问控制，排成多个队，没有冲突的地方进行并行：读写均加锁，</li>
<li>针对读场景做优化，读与写锁分离开，读进行并行操作：提升读多写少性能，即读写锁，可重复读</li>
<li>MVCC，多版本并发控制，写不阻塞读，copy on write，写读场景优化，写的时候可以读，只有写写时冲突，系统实现复杂性变高，日志变多。</li>
</ul>
<p>ACID 中的 I，隔离级别，但为了并发而破坏了一致性：</p>
<ul>
<li>可序列化</li>
<li>可重复读</li>
<li>读已提交</li>
</ul>
<h3 id=事务处理的常见问题>事务处理的常见问题</h3>
<h4 id=事务顺序>事务顺序</h4>
<p>MVCC中，每次数据写入都放入不同版本的数据log，如何保证写写读的顺序。</p>
<p>内存中维持数据自增号，写的时候加1。读的时候根据ID找对应的数据。逻辑时间戳(事务单元先后)、物理时间戳(时钟)。</p>
<h4 id=故障恢复>故障恢复</h4>
<p>错误类型：</p>
<ul>
<li>业务属性不匹配，记录操作的反向操作，进行回退</li>
<li>系统崩溃，在数据恢复没有完全完成时不对外不服务，防止崩溃时没有完成的事务而造成的中间数据暴露</li>
</ul>
<h4 id=死锁怎么办>死锁怎么办</h4>
<p>原因：</p>
<ul>
<li>两个线程</li>
<li>不同方向</li>
<li>相同资源</li>
</ul>
<p>方法：</p>
<ul>
<li>尽可能不死锁，降低隔离级别</li>
<li>碰撞检测，记录各单元持有的锁进行检查，终止一边</li>
<li>等锁超时，但是超长事务导致每次死锁释放需要太久时间，2是主流，这个辅助</li>
</ul>
<h3 id=深入单机事务>深入单机事务</h3>
<h4 id=acid>ACID</h4>
<p>原子性操作：要么同时成功要么同时失败，回滚到事务最初状态。执行每个操作都记录一个回滚段。</p>
<p>一致性：核心为“看”，happen before，一个事务单元保证全部成功以后才可见。对多个事务操作的同一数据加锁，将事务顺序化，排队，同时将锁下推到数据上，将锁分离，而不是一个超级大锁。</p>
<p>隔离性：因为一致性中加锁而带来的性能问题，对强一致性进行破坏。</p>
<ul>
<li>序列化读写，用排他锁，将所有读写操作排队：性能差==不可用</li>
<li>读写锁，读锁不能被写锁升级(读的时候不能写)：
<ul>
<li>可重复读，读读操作并行</li>
</ul>
</li>
<li>读写锁，读已提交，读锁能被写锁升级(读的时候能写)：
<ul>
<li>读读并行</li>
<li>读写并行</li>
</ul>
</li>
<li>读未提交，只加写锁，不加读锁
<ul>
<li>读读并行</li>
<li>读写并行</li>
<li>写读并行，所有的写是串行的，读都是并行的，可以读到写过程中未提交的数据（因此不建议用）</li>
</ul>
</li>
<li>MVCC，打脸上面的 SQL92标准。快照隔离级别，核心：copy on write+无锁编程，针对读多写少优化
<ul>
<li>每个事务都有一个版本号</li>
<li>新的事务同时进来后生成一个新的版本号，读取上一个版本号事务开始之前的数据</li>
<li>在读一致性数据的同时实现读未提交</li>
</ul>
</li>
</ul>
<p>持久性：事务完成后，所有的提交都要物理存储。延迟与持久性平衡。</p>
<ul>
<li>
<p>（操作 -> 内存 -> 磁盘(块越大越块)，如果在内存中攒成一块再写磁盘）</p>
</li>
<li>
<p>等待多次 commit 之后(group commit)再刷磁盘，攒成一大块，但吞吐变小，需要权衡</p>
</li>
<li>
<p>RAID 保证持久性：RAID controller 同时写到多个磁盘，同时成功同时失败，这又成为一个新的事务。</p>
</li>
</ul>
<h4 id=典型异常应对策略>典型异常应对策略</h4>
<p>业务属性不匹配：</p>
<ul>
<li>原子性</li>
<li>一致性</li>
<li>回滚：事务单元中的每个操作都记录一个回滚段</li>
</ul>
<p>系统宕机：重启后进入 recovery 模式，执行回滚段</p>
<h4 id=调优原则>调优原则</h4>
<p>在不影响业务应用的前提下：</p>
<ul>
<li>减少锁的覆盖范围(减小锁粒度)
<ul>
<li>myisam 表锁 -> innodb 行锁</li>
<li>原位锁 -> mvcc 多版本(将一个大锁拆分到不同版本的数据上)</li>
</ul>
</li>
<li>增加锁上可并行的线程数
<ul>
<li>读锁写锁分离、允许并行读取数据</li>
</ul>
</li>
<li>选择正确的锁类型，与读写锁是不同层次的概念（共两种锁：排他锁，共享锁）
<ul>
<li>悲观锁，适合并发争抢比较严重的场景</li>
<li>乐观锁，适合并发争抢不太严重的场景</li>
</ul>
</li>
</ul>
<blockquote>
<p>数据库中的 U 锁(update 锁)：如果事务单元中有写操作，则在进行读操作时直接申请为写锁，而不是读锁。</p>
</blockquote>
<h3 id=分布式事务与单机事务>分布式事务与单机事务</h3>
<p>分布式事务的目标：</p>
<ul>
<li>完整的事务支持，和单机一样</li>
<li>无限扩展</li>
</ul>
<h4 id=事务>事务</h4>
<p>(对于共享数据，)让多步操作顺序发生，让多线程看上去就像一步操作。</p>
<p>事务优化：尽可能的快，数据又不错乱。</p>
<h4 id=网络>网络</h4>
<p>优点：去中心化，网络提供了理论上无限的扩展能力，理论上无线的数据安全性(不丢失)，理论上无线的服务可用性。</p>
<p>缺点：共享数据困难(通过消息复制)，更多的延迟，确定性丧失，并发编程难度。</p>
<h4 id=基于锁的事务遇到的问题>基于锁的事务遇到的问题</h4>
<h5 id=从-2pl-到-2pc>从 2PL 到 2PC</h5>
<p>所有的数据库都会抽象为两阶段锁的操作。在分布式中抽象为两阶段提交。</p>
<p>由第三者-协调器负责跨机提交。</p>
<h5 id=分布式事务异常处理>分布式事务异常处理</h5>
<p>任何步骤出现状况时全部回滚。但是当一阶段已提交并暴露后，二阶段提交失败则无法再回滚，只能等待直到处理成功。</p>
<h5 id=分布式日志记录>分布式日志记录</h5>
<p>协调者高可用：</p>
<ul>
<li>必须是多机，任意协调者必须知道这个事务运行的状态</li>
<li>记录日志，准备阶段需要记录一次日志</li>
<li>每个节点的commit 都必须记录日志</li>
</ul>
<h5 id=分布式事务延迟变大>分布式事务延迟变大</h5>
<p>随着数据、节点增长，延迟越来越大，即分布式事务的最大问题。</p>
<h4 id=基于-mvcc-的事务视线中遇到的问题>基于 MVCC 的事务视线中遇到的问题</h4>
<h5 id=分布式顺序问题>分布式顺序问题</h5>
<p>逻辑时间戳，所有操作都需要一个时间戳，然后才能知道该操作需要操作的数据版本，以保证操作顺序。</p>
<p>但是分布式中无法再进行时间戳的分配了，单台机器分配的话将成为单点，同时，单位时间内能够分配的时间戳是有限的，比如一台机器为100台机器分配时间戳。多台又无法保证递增性。</p>
<h3 id=分布式事务的主要难题>分布式事务的主要难题</h3>
<h3 id=传统数据库的分布式事务>传统数据库的分布式事务</h3>
<h3 id=google-spanner-赏析>Google Spanner 赏析</h3>
<h3 id=阿里分布式事务模型>阿里分布式事务模型</h3>
<h3 id=drdstddl-实战>DRDS/TDDL 实战</h3>
<p>《youku：事务与分布式事务原理与实现》</p>
<p><a href=https://draveness.me/distributed-transaction-principle>https://draveness.me/distributed-transaction-principle</a></p>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-32e7ec0298beb63dbf02b847a8c13b0a>15 - 分布式锁</h1>
<h2 id=前情提要>前情提要</h2>
<p>基于分布式的 CAP (一致性、可用性、容错性)原理，系统在设计之初必须要考虑取舍，在互联网领域的绝大多数场景中，一般会牺牲强一致性来换取高可用性，只需要保证最终一致性即可，而这个最终一致的时间是用户可接受的范围即可。</p>
<p>为了保证最终一致性，一般会使用分布式事务、分布式锁等，分布式锁也有多种实现方案：</p>
<ul>
<li>基于数据库</li>
<li>基于缓存</li>
<li>基于 zookeeper</li>
</ul>
<p>分布式锁的实现目标：</p>
<ul>
<li>可以保证在分布式部署的应用集群中，同一个方法在同一时间只能被一台机器上的一个线程执行；</li>
<li>必须是可重入锁，以避免死锁</li>
<li>可以根据业务决定是不是一个阻塞锁</li>
<li>有高可用的加锁解锁功能</li>
<li>加锁解锁操作的性能要高</li>
</ul>
<h2 id=基于数据库>基于数据库</h2>
<h3 id=基于表>基于表</h3>
<p>在数据库中创建表，要锁住某个方法或资源时，在表中增加一条记录，想要释放时删除该记录。</p>
<p>创建表：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#204a87;font-weight:700>CREATE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>TABLE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>methodLock</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000;font-weight:700>(</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>id</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87>int</span><span style=color:#000;font-weight:700>(</span><span style=color:#0000cf;font-weight:700>11</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>NOT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>NULL</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>AUTO_INCREMENT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>COMMENT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;主键&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>method_name</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87>varchar</span><span style=color:#000;font-weight:700>(</span><span style=color:#0000cf;font-weight:700>64</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>NOT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>NULL</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>DEFAULT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;&#39;</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>COMMENT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;锁定的方法名&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#204a87;font-weight:700>desc</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87>varchar</span><span style=color:#000;font-weight:700>(</span><span style=color:#0000cf;font-weight:700>1024</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>NOT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>NULL</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>DEFAULT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;备注信息&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>update_time</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>timestamp</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>NOT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>NULL</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>DEFAULT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>CURRENT_TIMESTAMP</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>ON</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>UPDATE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>CURRENT_TIMESTAMP</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>COMMENT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#4e9a06>&#39;保存数据时间，自动生成&#39;</span><span style=color:#000;font-weight:700>,</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>PRIMARY</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>KEY</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000;font-weight:700>(</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>id</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000;font-weight:700>),</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline>  </span><span style=color:#204a87;font-weight:700>UNIQUE</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>KEY</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>uidx_method_name</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000;font-weight:700>(</span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000>method_name</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>`</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>USING</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>BTREE</span><span style=color:#f8f8f8;text-decoration:underline>
</span><span style=color:#f8f8f8;text-decoration:underline></span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>ENGINE</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#000>InnoDB</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>DEFAULT</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>CHARSET</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#000>utf8</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>COMMENT</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;锁定中的方法&#39;</span><span style=color:#000;font-weight:700>;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></code></pre></div><p>加锁操作：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#204a87;font-weight:700>insert</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>into</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>methodLock</span><span style=color:#000;font-weight:700>(</span><span style=color:#000>method_name</span><span style=color:#000;font-weight:700>,</span><span style=color:#204a87;font-weight:700>desc</span><span style=color:#000;font-weight:700>)</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>values</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000;font-weight:700>(</span><span style=color:#a40000>‘</span><span style=color:#000>method_name</span><span style=color:#a40000>’</span><span style=color:#000;font-weight:700>,</span><span style=color:#a40000>‘</span><span style=color:#204a87;font-weight:700>desc</span><span style=color:#a40000>’</span><span style=color:#000;font-weight:700>);</span><span style=color:#f8f8f8;text-decoration:underline>
</span></code></pre></div><p>解锁操作：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sql data-lang=sql><span style=color:#204a87;font-weight:700>delete</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>from</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>methodLock</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#204a87;font-weight:700>where</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#000>method_name</span><span style=color:#f8f8f8;text-decoration:underline> </span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#4e9a06>&#39;method_name&#39;</span><span style=color:#000;font-weight:700>;</span><span style=color:#f8f8f8;text-decoration:underline>
</span></code></pre></div><p>缺点：</p>
<ul>
<li>这把锁强依赖于数据库的高可用性；</li>
<li>锁没有失效时间，一旦解锁操作失败，将导致其他线程无法再获得锁；</li>
<li>这把锁只能是非阻塞的，因为数据的插入操作一旦失败就会返回报错。没有获得锁的线程并不会排队进入队列，想要再次获得锁就要再次出发获得锁操作；</li>
<li>这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为表中数据已经存在了。</li>
</ul>
<p>解决方法：</p>
<ul>
<li>使用分布式数据库；</li>
<li>使用定时任务，按时清理超时的锁；</li>
<li>通过 while 循环直到插入成功；</li>
<li>添加字段，记录当前获得锁的主机的信息和线程信息，然后在下次获取锁时先查询，如果信息匹配则分配锁。</li>
</ul>
<h3 id=基于数据库排它锁>基于数据库排它锁</h3>
<p>基于 MySQL 中 InnoDB 自带的排它锁实现加锁：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=color:#204a87;font-weight:700>public</span> <span style=color:#204a87;font-weight:700>boolean</span> <span style=color:#000>lock</span><span style=color:#ce5c00;font-weight:700>(){</span>
    <span style=color:#000>connection</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#c4a000>setAutoCommit</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#204a87;font-weight:700>false</span><span style=color:#ce5c00;font-weight:700>)</span>
    <span style=color:#204a87;font-weight:700>while</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#204a87;font-weight:700>true</span><span style=color:#ce5c00;font-weight:700>){</span>
        <span style=color:#204a87;font-weight:700>try</span><span style=color:#ce5c00;font-weight:700>{</span>
            <span style=color:#000>result</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>select</span> <span style=color:#ce5c00;font-weight:700>*</span> <span style=color:#000>from</span> <span style=color:#000>methodLock</span> <span style=color:#000>where</span> <span style=color:#000>method_name</span><span style=color:#ce5c00;font-weight:700>=</span><span style=color:#000>xxx</span> <span style=color:#204a87;font-weight:700>for</span> <span style=color:#000>update</span><span style=color:#ce5c00;font-weight:700>;</span>
            <span style=color:#204a87;font-weight:700>if</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#000>result</span><span style=color:#ce5c00;font-weight:700>==</span><span style=color:#204a87;font-weight:700>null</span><span style=color:#ce5c00;font-weight:700>){</span>
                <span style=color:#204a87;font-weight:700>return</span> <span style=color:#204a87;font-weight:700>true</span><span style=color:#ce5c00;font-weight:700>;</span>
            <span style=color:#ce5c00;font-weight:700>}</span>
        <span style=color:#ce5c00;font-weight:700>}</span><span style=color:#204a87;font-weight:700>catch</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#000>Exception</span> <span style=color:#000>e</span><span style=color:#ce5c00;font-weight:700>){</span>

        <span style=color:#ce5c00;font-weight:700>}</span>
        <span style=color:#000>sleep</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#000>1000</span><span style=color:#ce5c00;font-weight:700>);</span>
    <span style=color:#ce5c00;font-weight:700>}</span>
    <span style=color:#204a87;font-weight:700>return</span> <span style=color:#204a87;font-weight:700>false</span><span style=color:#ce5c00;font-weight:700>;</span>
<span style=color:#ce5c00;font-weight:700>}</span>
</code></pre></div><p>在查询语句后面增加<code>for update</code>，数据库会在查询过程中给数据库表增加排它锁，当某条记录被加上排它锁之后，其他线程则无法再在该记录上增加排它锁。</p>
<blockquote>
<p>InnoDB 引擎在加锁的时候，只有通过索引进行检索的时候才会使用行级锁，否则会使用表级锁。这里我们希望使用行级锁，就要给<code>method_name</code>添加索引，同时一定要创建成唯一索引，否则会出现多个重载方法之间无法同时被访问的问题，重载方法的话建议同时保存参数类型。</p>
</blockquote>
<p>这时可以认为获得排他锁的线程即获得了分布式锁，当获取到锁之后，可以执行方法的业务逻辑，最后再进行解锁操作：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=color:#204a87;font-weight:700>public</span> <span style=color:#204a87;font-weight:700>void</span> <span style=color:#000>unlock</span><span style=color:#ce5c00;font-weight:700>(){</span>
    <span style=color:#000>connection</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#c4a000>commit</span><span style=color:#ce5c00;font-weight:700>();</span>
<span style=color:#ce5c00;font-weight:700>}</span>
</code></pre></div><p>这种方式可以有效解决上面提到的无法解锁和阻塞锁的问题。</p>
<ul>
<li>阻塞锁：<code>for update</code>语句会在执行成功之后立即返回，在执行失败时一直处于阻塞状态，直到成功；</li>
<li>锁定之后服务宕机造成的无法释放：这种方式下，服务宕机时数据库会自动释放锁。</li>
</ul>
<p>但是仍然无法解决单点问题和可重入问题。</p>
<p>另一个问题：虽然对<code>method_name</code>使用了唯一索引，并且显式使用<code>for update</code>来使用行级别锁。但是，MySQL 会对查询进行优化，即便在条件中使用了索引字段，但是否使用索引来检索数据仍然是由 MySQL 通过判断不同执行计划的代价来决定的，如果 MySQL 自认为扫表效率更高，比如对一些很小的表，则不会使用索引，这是将会使用表锁而不是行锁。。。</p>
<p>同时，我们要使用排它锁来进行分布式锁的 lock，那么一个排它锁长时间不提交就会占用数据库连接，连接过多则造成数据库不可用。</p>
<h2 id=基于缓存>基于缓存</h2>
<p>基于类似 Redis、Memcached、Tair等缓存时，性能会表现更好。</p>
<p>比如在 Tair 中使用<code>TairManager.put</code>进行加锁和解锁操作：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=color:#204a87;font-weight:700>public</span> <span style=color:#204a87;font-weight:700>boolean</span> <span style=color:#000>trylock</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#000>String</span> <span style=color:#000>key</span><span style=color:#ce5c00;font-weight:700>)</span> <span style=color:#ce5c00;font-weight:700>{</span>
    <span style=color:#000>ResultCode</span> <span style=color:#000>code</span> <span style=color:#ce5c00;font-weight:700>=</span> <span style=color:#000>ldbTairManager</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#c4a000>put</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#000>NAMESPACE</span><span style=color:#ce5c00;font-weight:700>,</span> <span style=color:#000>key</span><span style=color:#ce5c00;font-weight:700>,</span> <span style=color:#4e9a06>&#34;This is a Lock.&#34;</span><span style=color:#ce5c00;font-weight:700>,</span> <span style=color:#000>2</span><span style=color:#ce5c00;font-weight:700>,</span> <span style=color:#000>0</span><span style=color:#ce5c00;font-weight:700>);</span>
    <span style=color:#204a87;font-weight:700>if</span> <span style=color:#ce5c00;font-weight:700>(</span><span style=color:#000>ResultCode</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#c4a000>SUCCESS</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#c4a000>equals</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#000>code</span><span style=color:#ce5c00;font-weight:700>))</span>
        <span style=color:#204a87;font-weight:700>return</span> <span style=color:#204a87;font-weight:700>true</span><span style=color:#ce5c00;font-weight:700>;</span>
    <span style=color:#204a87;font-weight:700>else</span>
        <span style=color:#204a87;font-weight:700>return</span> <span style=color:#204a87;font-weight:700>false</span><span style=color:#ce5c00;font-weight:700>;</span>
<span style=color:#ce5c00;font-weight:700>}</span>
<span style=color:#204a87;font-weight:700>public</span> <span style=color:#204a87;font-weight:700>boolean</span> <span style=color:#000>unlock</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#000>String</span> <span style=color:#000>key</span><span style=color:#ce5c00;font-weight:700>)</span> <span style=color:#ce5c00;font-weight:700>{</span>
    <span style=color:#000>ldbTairManager</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#c4a000>invalid</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#000>NAMESPACE</span><span style=color:#ce5c00;font-weight:700>,</span> <span style=color:#000>key</span><span style=color:#ce5c00;font-weight:700>);</span>
<span style=color:#ce5c00;font-weight:700>}</span>
</code></pre></div><p>同样会存在的问题：</p>
<ul>
<li>锁没有失效时间；</li>
<li>只能是非阻塞的，无论成功失败都会直接返回；</li>
<li>是非重入的，一个线程获得锁之后，在释放之前，都无法再获得锁，因为使用的 KEY 在 缓存中已存在，无法再次进行 put 操作。</li>
</ul>
<p>解决方式：</p>
<ul>
<li>put 时设置过期时间；</li>
<li>while 重复执行知道成功；</li>
<li>保存主机和线程信息。</li>
</ul>
<p>但是失效时间设计为多久合适呢？太短的话还没执行完就自动释放了，太久则浪费时间。</p>
<h2 id=基于-zk>基于 ZK</h2>
<p>基于 ZK 临时有序节点来实现分布式锁。</p>
<p>每个客户端对某个方法加锁时，在 ZK 中的与该方法对应的指定节点的目录下，生成一个唯一的瞬时有序节点。判断是否获取锁的方式很简单，只需要判断有序节点中序号最小的一个。当释放锁的时候，只需要将这个节点删除即可。同时可以避免因宕机而造成的死锁。</p>
<p>是否能解决其他实现遇到的问题：</p>
<ul>
<li>可以有效解决无法释放问题，因为在创建锁的时候，客户端会在 ZK 中创建一个临时节点，一点客户端宕机则 session 连接断开，这时临时节点会自动删除，其他客户端会再次获得锁。</li>
<li>阻塞锁：客户端通过在 ZK 中创建顺序节点，并且在节点中绑定监听器，一旦节点有变化，ZK 会通知客户端，客户端可以检查自己创建的节点是不是当前所有节点中需要最小的，如果是，那么自己就获得锁。</li>
<li>可重入：客户端在创建节点时同时保存主机与线程信息，下次想要获取时和当前最小节点中的信息进行对比即可，相同则获得锁，不同在创建一个新的节点来进行排队。</li>
<li>单点：ZK 本身就作为高可用集群部署。</li>
</ul>
<p>同时可以直接使用 ZK 的三方库 Curator 客户端，这个客户端中已经封装了一个可重入锁服务：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-java data-lang=java><span style=color:#204a87;font-weight:700>public</span> <span style=color:#204a87;font-weight:700>boolean</span> <span style=color:#000>tryLock</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#204a87;font-weight:700>long</span> <span style=color:#000>timeout</span><span style=color:#ce5c00;font-weight:700>,</span> <span style=color:#000>TimeUnit</span> <span style=color:#000>unit</span><span style=color:#ce5c00;font-weight:700>)</span> <span style=color:#204a87;font-weight:700>throws</span> <span style=color:#000>InterruptedException</span><span style=color:#ce5c00;font-weight:700>{</span>
  <span style=color:#204a87;font-weight:700>try</span><span style=color:#ce5c00;font-weight:700>{</span>
    <span style=color:#204a87;font-weight:700>return</span> <span style=color:#000>interProcessMutex</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#c4a000>acquire</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#000>timeout</span><span style=color:#ce5c00;font-weight:700>,</span> <span style=color:#000>unit</span><span style=color:#ce5c00;font-weight:700>);</span>
  <span style=color:#ce5c00;font-weight:700>}</span> <span style=color:#204a87;font-weight:700>catch</span> <span style=color:#ce5c00;font-weight:700>(</span><span style=color:#000>Exception</span> <span style=color:#000>e</span><span style=color:#ce5c00;font-weight:700>){</span>
    <span style=color:#000>e</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#c4a000>printStackTrace</span><span style=color:#ce5c00;font-weight:700>();</span>
  <span style=color:#ce5c00;font-weight:700>}</span>
  <span style=color:#204a87;font-weight:700>return</span> <span style=color:#204a87;font-weight:700>true</span><span style=color:#ce5c00;font-weight:700>;</span>
<span style=color:#ce5c00;font-weight:700>}</span>

<span style=color:#204a87;font-weight:700>public</span> <span style=color:#204a87;font-weight:700>boolean</span> <span style=color:#000>unlock</span><span style=color:#ce5c00;font-weight:700>(){</span>
  <span style=color:#204a87;font-weight:700>try</span><span style=color:#ce5c00;font-weight:700>{</span>
    <span style=color:#000>interProcessMutex</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#c4a000>release</span><span style=color:#ce5c00;font-weight:700>();</span>
  <span style=color:#ce5c00;font-weight:700>}</span><span style=color:#204a87;font-weight:700>catch</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#000>Throwable</span> <span style=color:#000>e</span><span style=color:#ce5c00;font-weight:700>){</span>
    <span style=color:#000>log</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#c4a000>error</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#000>e</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#c4a000>getMessage</span><span style=color:#ce5c00;font-weight:700>(),</span> <span style=color:#000>e</span><span style=color:#ce5c00;font-weight:700>)</span>
  <span style=color:#ce5c00;font-weight:700>}</span> <span style=color:#204a87;font-weight:700>finally</span><span style=color:#ce5c00;font-weight:700>{</span>
    <span style=color:#000>executorService</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#c4a000>schedule</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#204a87;font-weight:700>new</span> <span style=color:#000>Cleaner</span><span style=color:#ce5c00;font-weight:700>(</span><span style=color:#000>client</span><span style=color:#ce5c00;font-weight:700>,</span> <span style=color:#000>path</span><span style=color:#ce5c00;font-weight:700>),</span> <span style=color:#000>delayTimeForClean</span><span style=color:#ce5c00;font-weight:700>,</span> <span style=color:#000>TimeUnit</span><span style=color:#ce5c00;font-weight:700>.</span><span style=color:#c4a000>MILLISECONDS</span><span style=color:#ce5c00;font-weight:700>);</span>
  <span style=color:#ce5c00;font-weight:700>}</span>
  <span style=color:#204a87;font-weight:700>return</span> <span style=color:#204a87;font-weight:700>true</span><span style=color:#ce5c00;font-weight:700>;</span>
<span style=color:#ce5c00;font-weight:700>}</span>
</code></pre></div><p>只是基于 ZK 的实现在性能上达不到基于缓存的实现，这是由 ZK 的分布式机制决定的(Leader 执行再同步到所有 follower)。</p>
<p>同时可能带来并发问题，只是不常见而已。比如，由于网络抖动，客户端与 ZK 集群的 session 断开了，那么 ZK 会以为客户端挂了，这时删除临时节点，这时其他节点则获得了锁，则可能产生并发问题。不常见是因为 ZK 有重试机制，一旦 ZK 集群检测不到客户端心跳就会进行重试，Curator 客户端支持多种尝试策略，多次重试仍然不行则删除临时节点。</p>
<h2 id=总结>总结</h2>
<p>从理解的难以程度(由低到高)：数据库 - 缓存 - ZK</p>
<p>从实现复杂度(由低到高)：ZK -= 缓存 - 数据库</p>
<p>性能角度(由高到低)：缓存 - ZK -= 数据库</p>
<p>可靠性(由高到低)：ZK - 缓存 - 数据库</p>
<h2 id=todo>TODO</h2>
<ul>
<li><a href="https://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng==&mid=2247488964&amp;amp;idx=1&amp;amp;sn=f9a39b244202656a2dcc2c9705190a74&source=41#wechat_redirect">https://mp.weixin.qq.com/s?__biz=MzI4MTY5NTk4Ng==&mid=2247488964&amp;amp;idx=1&amp;amp;sn=f9a39b244202656a2dcc2c9705190a74&source=41#wechat_redirect</a></li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-cd6eab4d11b89cc125c95366a63cbaa1>16 - 一致性与共识算法</h1>
<h2 id=分布式一致性>分布式一致性</h2>
<p>在一个分布式系统中，如何保证集群中所有节点中的数据完全相同，并且能够对某个提案(Proposal)达成一致，是分布式系统正常工作的核心问题，而共识算法就是用来保证分布式系统一致性的方法。</p>
<p>然而分布式系统中由于引入了多个节点，所以系统中会出现各种非常复杂的情况；随着节点数量增加，节点失效、故障或者宕机就变成了非常常见的事情，解决分布式系统中的各种边界条件和意外情况也增加了解决分布式一致性问题的难度。</p>
<p>在一个分布式系统中，除了节点的失效会是会导致一致性不容易达成的主要原因之外，节点之间的网络通信受到干扰甚至阻断，以及分布式系统的运行速度的差异都是解决分布式系统一致性所面临的难题。</p>
<h3 id=cap>CAP</h3>
<p>在 1998 年秋，加州伯克利大学的教授 Eric Brewer 第一次发布了 CAP 理论，在 1999 年论文 “<a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.6951&rep=rep1&type=pdf">Brewer&rsquo;s Conjecture and the Feasibility of Consitent, Available, Partition-Tolerant Web Service</a>” 正式发布，其中总结了 Eric Brewer 提出的 CAP 理论。</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/2018021615187855658956.png style=display:block;width:50% alt=NAME align=center> </div>
<p>该论文证明了两个非常有意思的理论：首先是在异步网络模型中，所有的节点都是由于没有时钟，仅能根据接收到的消息做出判断，这时完全不能保证一致性、可用性、分区容错性，<strong>每个系统仅能在这三种特性中选择两种。</strong></p>
<p>这里讨论的一致性都是<strong>强一致性</strong>，即所有节点接收到同样的操作时会按照完全相同的顺序执行，被一个节点提交的更新操作会立即反映在其他<strong>通过异步或部分同步网络连接的节点上，<strong>如果想要同时满足一致性和分区容错性，在异步网络中，我们只能</strong>中心化存储所有数据</strong>，通过其他节点将请求路由给中心节点达到这两个目的。</p>
<p>但是在现实世界中其实并不存在<strong>绝对异步</strong>的网络环境，如果我们允许每个节点拥有自己的时钟，这些时钟虽然有着各自不同的时间，但他们的**更新频率是完全相同的，**所以我们可以通过时钟得知接收消息的间隔时间，在这种更宽松的前提下，我们能够得到更加强大的服务。</p>
<p>然而在部分同步的网络环境中，仍然没有办法同时保证三种特性，证明的过程其实非常简单，可以直接阅读 <a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.6951&rep=rep1&type=pdf">论文的 4.2 节</a>，然而时钟的出现能够让我们知道当前消息有多久没有得到回应，通过超时时间就能在一定程度上解决信息丢失的问题。</p>
<p>由于网络一定会存在延时，所以没有办法在分布式系统中做到强一致性的同时保证可用性，不过我们可以通过降低对一致性的要求，在一致性和可用性之间做出权衡，而这其实也是设计分布式系统首先要考虑的问题，由于强一致性的系统会导致系统的可用性降低，仅仅将接受请求的工作交给其他节点对于高并发的服务并不能解决问题，所以在目前主流的分布式系统中都选择<strong>最终一致性</strong>。</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20180217151884412972134.png style=display:block;width:50% alt=NAME align=center> </div>
<p>最终一致性允许多个节点间的状态出现冲突，但是所有能够沟通的节点都能够在有限的时间内解决冲突，从不一致的状态恢复到一致。这里列出的两个条件比较重要：一是<strong>节点直接可以正常通信</strong>，而是冲突<strong>需要在有限时间内解决</strong>，只有在两个条件均成立时才能达到最终一致性。</p>
<h3 id=拜占庭将军问题>拜占庭将军问题</h3>
<p>该问题是 Leslie Lamport 在 <a href=https://web.archive.org/web/20170205142845/http://lamport.azurewebsites.net/pubs/byz.pdf>The Byzantine Generals Problem</a> 论文中提出的分布式领域的<strong>容错问题</strong>，它是分布式领域中最复杂、最严格的容错模型。</p>
<p>在该模型下，系统不会对集群中的节点做任何的限制，它们可以向其他节点发送随机数据、错误数据，也可以选择不响应其他节点的请求，这些无法预测的行为使得容错这一问题变得更加复杂。</p>
<p>拜占庭将军问题描述了如下的场景，有一组将军分别指挥一部分军队，每个将军都不知道其他将军是否是可靠的，也不知道其他将军传递的信息是否可靠，但是他们需要通过投票选择是否要进攻或撤退：</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20180217151884457569865.png style=display:block;width:50% alt=NAME align=center> </div>
<blockquote>
<p>本节中，黄色代表状态未知，绿色代表进攻，蓝色代表撤退，红色代表当前将军的信息不可靠。</p>
</blockquote>
<p>这时，无论将军是否可靠，只要所有的将军达成了统一的方案，选择进攻或撤退其实是没有任何问题的：</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20180217151884479414231.png style=display:block;width:50% alt=NAME align=center> </div>
<p>上述的情况不会对当前的战局造成太大影响，但是如果其中一个将军告诉其中一部分将军选择进攻，告诉另一部分将军选择撤退，就会出现非常严重的问题了。</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/2018021715188449147423.png style=display:block;width:50% alt=NAME align=center> </div>
<p>由于将军的队伍中出现了一个叛徒或者信息在传递的过程中被拦截，会导致一部分将军会选择进攻，剩下的一份会选择撤退，他们都认为自己的选择是大多数人的选择，这时会出现严重的不一致问题。</p>
<p>拜占庭将军问题是对分布式系统容错的最高要求，然而这不是日常工作中使用的大多数分布式系统中会面对的问题，我们遇到更多的还是节点故障宕机或者不响应等情况，这就大大简化了系统对容错的要求；不过类似 Bitcoin、Ethereum 等分布式系统确实需要考虑拜占庭容错的问题，我们会在下面介绍它们是如何解决的。</p>
<h3 id=flp>FLP</h3>
<p>FLP 不可能定理是分布式系统领域最重要的定理之一，它给出了一个非常重要的结论：<strong>在网络可靠且存在节点失效的异步模型系统中，不存在一个可以解决一致性问题的确定性算法。</strong></p>
<blockquote>
<p>In this paper, we show the surprising result that no completely asynchronous consensus protocol can tolerate even a single unannounced process death. We do not consider Byzantine failures, and we assume that the message system is reliable it delivers all messages correctly and exactly once.</p>
</blockquote>
<p>这个定理其实也就是告诉我们不要浪费时间去为异步分布式系统设计在任意场景上都能实现的共识算法，异步系统完全没办法保证在有限时间内达成一致，在这里作者并不会去尝试证明 FLP 不可能定理，读者可以阅读相关论文 <a href=https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf>Impossibility of Distributed Consensuswith One Faulty Process</a> 了解更多内容。</p>
<h2 id=共识算法>共识算法</h2>
<p>在上节中，我们已经简单了解了分布式系统中面对的问题与挑战，在这里我们会介绍不同共识算法的实现原理，包括传统分布式领域的 Paxos、Raft，以及加密货币中使用的工作量证明(POW)、权益证明(POS)和委托权益证明(DPOS)，通过对这些共识算法原理的介绍和分析，我相信各位读者能对分布式一致性和共识算法有更深的理解。</p>
<h3 id=paxos-与-raft>Paxos 与 Raft</h3>
<p>Paxos 和 Raft 是目前分布式系统领域中两种非常著名的解决一致性问题的共识算法，两者都能解决分布式系统中的一致性问题，但是前者的实现与证明非常难以理解，后者的实现比较简洁并且遵循人类的直觉，它的出现就是为了解决 Paxos 难以理解并难以实现的问题。</p>
<p>我们先来简单介绍一下 <a href=https://en.wikipedia.org/wiki/Paxos_(computer_science)>Paxos</a> 究竟是什么。Paxos 其实是<strong>一类</strong>能够解决分布式一致性问题的协议，它能够让分布式网络中的节点在出现错误时仍然保持一致；Leslie Lamport 提出的 Paxos 可以在没有恶意节点的前提下保证系统中节点的一致性，也是第一个被证明完备的共识算法，目前<strong>完备</strong>的共识算法包括 Raft 本质上都是 Paxos 的变种。</p>
<p>作为一类协议，Paxos 中包括 Bais Paxos、Multi-Paxos、Cheap Paxos 和其他变种，这里我们会简单介绍 Basic Paxos 和 Multi-Paxos 这两种协议。</p>
<h4 id=basic-paxos>Basic Paxos</h4>
<p>Basic Paxos 是 Paxos 中最为基础的协议，每个 Basic Paxos 的协议实例最终都会选择唯一一个结果；使用 Paxos 作为共识算法的分布式系统中，节点都会有三种身份，分别是 Proposer、Acceptor、Learner。</p>
<p>我们在这里会忽略最后一种身份 Learner 以简化协议的运行过程、便于理解；Paxos 的运行过程分为两个阶段，分别是准备阶段(Prepare) 和接受阶段(Accept)，当 Proposer 接收到来自客户端的请求时，就会进入如下流程：</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20180217151884849371114.png style=display:block;width:50% alt=NAME align=center> </div>
<blockquote>
<p>图片来自 <a href=https://ramcloud.stanford.edu/~ongaro/userstudy/paxos.pdf>Paxos lecture (Raft user study)</a> 第 12 页。</p>
</blockquote>
<p>在整个共识算法运行的过程中，Proposer 负责提出提案并向 Acceptor 分别发出两次 RPC 请求，Prepare 和 Accept；Acceptor 会根据其持有的信息 minProposal、acceptedProposal、acceptValue，来选择接受或拒绝当前的提案，当某一个提案被过半数的 Acceptor 接受之后，我们就认为当前提案被整个集群接受了。</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/2018021715188487332940.png style=display:block;width:50% alt=NAME align=center> </div>
<p>我们简单举一个例子来介绍 Paxos 是如何在多个提案下保证最终能够达到一致性的，上图中 S1 和 S5 分别接收到了来自客户端的请求 X 和 Y，S1 首先向 S2 和 S3 发出 Prepare RPC 和 Accept RPC，三个服务器都接受了 S1 的提案；之后，S5 向 S3 和 S4 服务器发出 Prepare(2.5) 的请求，S3 由于已经接受了 X，所以他会返回接受的提案和值 (1.1, X)，这时服务器使用接收到的提案代替自己的提案 Y，重新向其他服务器发送 Accept(2.5 X) 的 RPC，最终所有的服务器会达成一致并选择相同的值。</p>
<h4 id=multi-paxos>Multi-Paxos</h4>
<p>由于大多数分布式服务器都要接受一系列的值，如果使用 Basic Paxos 来处理数据流，那么就会导致非常明显的性能损失，而 Multi-Paxos 是前者的加强版，如果集群中的 Leader 是非常稳定的，那么我们往往不需要准备阶段的工作，这样就能将 RPC 的次数减少一半。</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20180217151884920428994.png style=display:block;width:50% alt=NAME align=center> </div>
<p>上图中描述的就是稳定阶段 Multi-Paxos 的处理过程，S1 是整个集群的 Leader，当其他的节点接收到来自客户端的请求时，都会将请求转发给 Leader 进行处理。</p>
<p>当然，Leader 角色的出现自然会带来另一个问题，也就是 Leader 究竟应该如何选举，在 <a href=http://140.123.102.14:8080/reportSys/file/paper/lei/lei_5_paper.pdf>Paxos Made Simple</a> 一文中并没有给出 Multi-Paxos 的具体实现方法和细节，所以不同的 Multi-Paxos 实现会有各种细微的差别。</p>
<h4 id=raft>Raft</h4>
<p>Raft 其实就是 Multi-Paxos 的一个变种，Raft 通过简化 Multi-Paxos 模型，实现了一种更易让人理解的共识算法，它们两者都能够对一系列连续的问题达成一致。</p>
<p>Raft 在 Multi-Paxos 的基础上做了两个限制，首先是 Raft 中追加日志的操作必须是连续的，而 Multi-Paxos 中追加日志的操作是并发的，但是对于节点内部的状态机来说两者都是有序的；第二就是 Raft 对 Leader 选举的条件做了限制，只有拥有最新、最全日志的节点才能够当选 Leader，但是 Multi-Paxos 由于任意节点都可以写日志，所以在选择 Leader 上么有什么限制，只是在选择 Leader 之后需要将 Leader 中的日志补全。</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20180217151885257638482.png style=display:block;width:50% alt=NAME align=center> </div>
<p>在 Raft 中，所有 Follower 的日志都是 Leader 的子集，而 Multi-Paxos 中的日志并不会做这个保证，由于 Raft 对日志追加的方式和选举过程进行了限制，所以在实现上会更加容易和简单。</p>
<p>从理论上来讲，支持并发日志追加的 Paxos 会比 Raft 拥有更加优秀的性能，不过其理解和实现上还是比较复杂的，很多人都会说 Paxos 是科学，而 Raft 是工程，当作者需要去实现一个共识算法，会选择使用 Raft 和更简洁的实现，避免因为一些边界条件带来的复杂问题。</p>
<p>可以查看 <a href=https://raft.github.io/>The Raft Consensus Algorithm</a> 了解更多 Raft 的细节。</p>
<h3 id=powproof-of-work>POW：Proof-of-Work</h3>
<p>上一节介绍的共识算法，无论是 Paxos 还是 Raft 其实都只能解决拜占庭将军问题的一致性问题，不能够应对分布式网络中出现的极端情况，但是这在传统的分布式系统都不是什么问题，无论分布式数据库还是消息队列集群，它们内部的节点并不会故意发送错误信息，在类似系统中，最常见的问题就是节点失去响应或失效，所以它们在这种情况下是有效可行的，也是充分的。</p>
<p>这一节介绍的 <a href=https://en.wikipedia.org/wiki/Proof-of-work_system>工作量证明</a> 是一个用于阻止拒绝服务攻击(DDOS)和类似垃圾邮件等服务错误问题的协议，它在 1993 年被 Cynthia Dwork 和 Moni Naor 提出，它能够帮助分布式系统达到拜占庭容错。</p>
<p>工作量证明的关键特点就是，分布式系统中的请求服务的节点必须解决一个<strong>一般难度但是可行(feasible)的问题</strong>，但是验证问题答案的过程对于服务提供者来说却非常容易，也就是一个不容易解答但是容易验证的问题。</p>
<p>这种问题通常需要消耗一定的 CPU 时间来计算某个问题的答案，目前最大的区块链网络-比特币(Bitcoin) 就使用了工作量证明的分布式一致性算法，在网络中的所有节点计算通过以下的谜题来获得当前区块的记账权：</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20180217151885399218765.png style=display:block;width:50% alt=NAME align=center> </div>
<p>SHA-256 作为一个哈希函数，想要通过 SHA-256 函数的输出推断输入在目前来看可能性是可以忽略不计的，比特币网络就需要每一个及诶单不断改变 NONCE 来得到不同的 HASH，如果得到的 HASH 结果在小于某个范围，目前(2017-12-17)的难度是：</p>
<div class=highlight><pre tabindex=0 style=background-color:#f8f8f8;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash>0x0000000000000000000000000000000000000000000000000000017268d8a21a
</code></pre></div><p>也就是说如果只计算一次 SHA-256 的值能够小于上述结果的可能性是 1.37 ∗ 10^-65，当前的全网算力也达到了 13,919 PH/s，这是个非常恐怖的数字，随着网络算力的不断改变，比特币也会不断改变当前问题的难度，保证每个区块被发现的时间在 10min 左右；整个比特币网络中，谁先得到当前问题的答案就能获得这个区块的记账权，并将当前区块通过 Gossip 协议发送给尽可能多的比特币节点。</p>
<p>工作量证明的原理其实非常简单，比特币网络选择的谜题非常好的适应了工作量证明定义中的问题，比较难以计算同时又易于验证，我们可以简单理解为工作量证明防止错误或者无效请求的原理就是增加客户端请求服务的工作量，而适合难度的谜题又能保证合法的请求不会受影响。</p>
<p>由于工作量证明需要消耗大量的算力，同时比特币大约 10min 才会产生一个区块，区块的大小也只有 1MB，仅仅能够包含 3-4000 笔交易，平均下来每秒只能够处理 5~7 笔交易，所以比特币网络的拥堵非常严重。</p>
<h3 id=posproof-of-stake>POS：Proof-of-Stake</h3>
<p>权益证明是区块链网络中使用的另一种共识算法，在基于权益证明的加密货币中，下一个区块的选择是根据不同节点的股份和时间随机进行的。</p>
<p>由于创造新的区块不会消耗大量的 CPU，如果它不诚实也不会造成什么损失，这也就给了很多节点作弊的理由，每个节点为了最大化利益会在多条链上同时挖矿。</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20180217151885486336299.png style=display:block;width:50% alt=NAME align=center> </div>
<p>在早期的所有权证明算法中，整个网络只会奖励创建区块的节点，不存在任何惩罚，这时每个节点在创造的多条链上同时投票才能够最大化利益，在这种情况下网络中的节点很难对一条链达成共识。</p>
<p>有两种办法能够解决缺乏厉害关系(nothing-at-stake)造成的问题，一种是使用 <a href=https://blog.ethereum.org/2014/01/15/slasher-a-punitive-proof-of-stake-algorithm/>Slasher</a> 协议，惩罚同时在多条链上投票的节点；第二种方法是直接惩罚在错误的链上创建块的节点，总而言之就是通过算法之外的手段来解决这个问题，引入激励和惩罚。</p>
<p>与工作量证明相比，权益证明不需要消耗大量的电力就能保证区块链网络的安全性，同时也不需要在每个区块中创建新的货币来激励旷工参与当前网络的运行，这也就在一定程度上缩短了达成共识所需要的时间，基于权益证明的 Ethereum 每秒大概处理 30 笔交易左右。</p>
<h3 id=dposdelegated-proof-of-stake>DPOS：Delegated Proof-of-Stake</h3>
<p>前面介绍的权益证明算法可以将整个区块链网络理解为一家公司，出资最多、占比最大的人又更多的机会得到话语权(记账权)；对于小股东来说，千分之几甚至万分之几的股份很难有什么作为，只能得到股份带来的分红和收益。</p>
<p>但是在这里介绍的委托权益证明能够让每个人选出可以代表自己利益的人参与到记账权的争夺中，这样多个小股东就能够通过投票选出自己的代理人，保障自己的利益。整个网络中选举出的多个节点能够在 1s 之内对 99.9% 的交易进行确认，使用委托权益证明的 EOS 能够每秒处理几十万笔交易，同时也能够比较监管的干预。</p>
<p>在委托权益证明中，每个参与者都能够选举任意数量的节点生成下一个区块，得票最多的前 N 个节点会被选择成为区块的创建者，下一个区块的创建者就会从这样一组当选者中随机选取，除此之外，N 的数量也是整个网络投票决定的，所以可以尽可能的保证网络的去中心化。</p>
<h2 id=reference>Reference</h2>
<ul>
<li><a href=https://en.wikipedia.org/wiki/Consensus_(computer_science)>Consensus (computer science)</a></li>
<li><a href=http://blog.csdn.net/lsttoy/article/details/61624287>区块链共识算法（POW,POS,DPOS,PBFT）介绍和心得</a></li>
<li><a href=https://yeasy.gitbooks.io/blockchain_guide/content/distribute_system/paxos.html>Paxos 与 Raft</a></li>
<li><a href=https://en.wikipedia.org/wiki/Proof-of-work_system>Proof-of-work system</a></li>
<li><a href=https://en.wikipedia.org/wiki/Proof-of-stake>Proof-of-stake</a></li>
<li><a href=https://github.com/ethereum/wiki/wiki/Proof-of-Stake-FAQ>Proof of Stake FAQ · Ethereum Wiki</a></li>
<li><a href=http://docs.bitshares.org/bitshares/dpos.html>Delegated Proof of Stake</a></li>
<li><a href=https://bitshares.org/technology/delegated-proof-of-stake-consensus/>Delegated Proof-of-Stake Consensus</a></li>
<li><a href=https://steemit.com/dpos/@legendx/dpos>DPOS共识算法 – 缺失的白皮书</a></li>
<li><a href=https://yeasy.gitbooks.io/blockchain_guide/content/distribute_system/consensus.html>共识算法</a></li>
<li><a href=https://en.wikipedia.org/wiki/CAP_theorem>CAP theorem</a></li>
<li><a href=http://140.123.102.14:8080/reportSys/file/paper/lei/lei_5_paper.pdf>Paxos Made Simple</a></li>
<li><a href=https://raft.github.io/>The Raft Consensus Algorithm</a></li>
<li><a href=https://raft.github.io/raft.pdf>In Search of an Understandable Consensus Algorithm</a></li>
<li><a href=https://baotiao.github.io/2016/05/05/paxos-raft/>谈谈 paxos, multi-paxos, raft</a></li>
<li><a href="http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.67.6951&rep=rep1&type=pdf">Brewer’s Conjecture and the Feasibility of Consistent, Available, Partition-Tolerant Web Services</a></li>
<li><a href=https://stackoverflow.com/questions/29381442/eventual-consistency-vs-strong-eventual-consistency-vs-strong-consistency>“Eventual Consistency” vs “Strong Eventual Consistency” vs “Strong Consistency”?</a></li>
<li><a href=https://groups.csail.mit.edu/tds/papers/Lynch/jacm85.pdf>Impossibility of Distributed Consensuswith One Faulty Process</a></li>
<li><a href=https://web.archive.org/web/20170205142845/http://lamport.azurewebsites.net/pubs/byz.pdf>The Byzantine Generals Problem</a></li>
<li><a href=https://en.wikipedia.org/wiki/Byzantine_fault_tolerance>Byzantine fault tolerance</a></li>
<li><a href=http://the-paper-trail.org/blog/a-brief-tour-of-flp-impossibility/>A Brief Tour of FLP Impossibility</a></li>
<li><a href=http://140.123.102.14:8080/reportSys/file/paper/lei/lei_5_paper.pdf>Paxos Made Simple</a></li>
<li><a href=http://harry.me/blog/2014/12/27/neat-algorithms-paxos/>Neat Algorithms - Paxos</a></li>
<li><a href=http://danielw.cn/FLP-proof>FLP Impossibility 的证明</a></li>
<li><a href=https://read.douban.com/ebook/42852957/>白话区块链</a></li>
<li><a href=https://en.wikipedia.org/wiki/Paxos_(computer_science)>Paxos</a></li>
<li><a href="https://www.youtube.com/watch?v=JEpsBg0AO6o">Paxos lecture (Raft user study)</a></li>
<li><a href=https://bitcoin.org/bitcoin.pdf>Bitcoin: A Peer-to-Peer Electronic Cash System</a></li>
<li><a href=https://en.bitcoin.it/wiki/Proof_of_Stake>Proof of Stake · Bitcoin Wiki</a></li>
<li><a href=https://blog.ethereum.org/2014/01/15/slasher-a-punitive-proof-of-stake-algorithm/>Slasher</a></li>
<li><a href=https://github.com/ethereum/wiki/wiki/Proof-of-Stake-FAQ>Proof of Stake FAQ</a></li>
</ul>
</div>
<div class=td-content style=page-break-before:always>
<h1 id=pg-5972a917bbf5042578567f6c7c1d5c11>17 - 一致性哈希算法</h1>
<p>当我们在做数据库分库分表或者是分布式缓存时，不可避免的都会遇到一个问题: <strong>如何将数据均匀的分散到各个节点中，并且尽量的在加减节点时能使受影响的数据最少。</strong></p>
<h2 id=hash-取模>Hash 取模</h2>
<p>随机放置就不说了，会带来很多问题。通常最容易想到的方案就是 hash 取模了。</p>
<p>可以将传入的 Key 按照 index = hash(key) % N 这样来计算出需要存放的节点。其中 hash 函数是一个将字符串转换为正整数的哈希映射方法，N 就是节点的数量。</p>
<p>这样可以满足数据的均匀分配，但是这个算法的容错性和扩展性都较差。比如增加或删除了一个节点时，所有的 Key 都需要重新计算，显然这样成本较高，为此需要一个算法满足分布均匀同时也要有良好的容错性和拓展性。</p>
<h2 id=一致-hash-算法>一致 Hash 算法</h2>
<p>一致 Hash 算法是将所有的哈希值构成了一个环，其范围在 0 ~ 2^32-1。如下图：</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190225003844.png style=display:block;width:50% alt=NAME align=center> </div>
<p>之后将各个节点散列到这个环上，可以用节点的 IP、hostname 这样的唯一性字段作为 Key 进行 hash(key)，散列之后如下：</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190225003904.png style=display:block;width:50% alt=NAME align=center> </div>
<p>之后需要将数据定位到对应的节点上，使用同样的 hash 函数 将 Key 也映射到这个环上。</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190225003923.png style=display:block;width:50% alt=NAME align=center> </div>
<p>这样按照顺时针方向就可以把 k1 定位到 N1节点，k2 定位到 N3节点，k3 定位到 N2节点。</p>
<h2 id=容错性>容错性</h2>
<p>这时假设 N1 宕机了：</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190225003956.png style=display:block;width:50% alt=NAME align=center> </div>
<p>依然根据顺时针方向，k2 和 k3 保持不变，只有 k1 被重新映射到了 N3。这样就很好的保证了容错性，当一个节点宕机时只会影响到少少部分的数据。</p>
<h2 id=拓展性>拓展性</h2>
<p>当新增一个节点时:</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190225004033.png style=display:block;width:50% alt=NAME align=center> </div>
<p>在 N2 和 N3 之间新增了一个节点 N4 ，这时会发现受印象的数据只有 k3，其余数据也是保持不变，所以这样也很好的保证了拓展性。</p>
<h2 id=虚拟节点>虚拟节点</h2>
<p>到目前为止该算法依然也有点问题。</p>
<p>当节点较少时会出现数据分布不均匀的情况：</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190225004110.png style=display:block;width:50% alt=NAME align=center> </div>
<p>这样会导致大部分数据都在 N1 节点，只有少量的数据在 N2 节点。</p>
<p>为了解决这个问题，一致哈希算法引入了虚拟节点。将每一个节点都进行多次 hash，生成多个节点放置在环上称为虚拟节点:</p>
<div align=center> <img src=https://infi-img.oss-cn-hangzhou.aliyuncs.com/img/20190225004157.png style=display:block;width:50% alt=NAME align=center> </div>
<p>计算时可以在 IP 后加上编号来生成哈希值。</p>
<p>这样只需要在原有的基础上多一步由虚拟节点映射到实际节点的步骤即可让少量节点也能满足均匀性。</p>
<ul>
<li><a href=https://crossoverjie.top/2018/01/08/Consistent-Hash/>一致 Hash 算法分析</a></li>
<li><a href=http://afghl.github.io/2016/11/19/implement-consistent-hashing.html>实现</a></li>
<li><a href=https://www.cnblogs.com/xrq730/p/5186728.html>一致性哈希 Java 实现的深入研究</a></li>
</ul>
</div>
</main>
</div>
</div>
<footer class="bg-dark py-5 row d-print-none">
<div class="container-fluid mx-sm-5">
<div class=row>
<div class="col-6 col-sm-4 text-xs-center order-sm-2">
</div>
<div class="col-6 col-sm-4 text-right text-xs-center order-sm-3">
<ul class="list-inline mb-0">
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Weibo aria-label=Weibo>
<a class=text-white target=_blank rel="noopener noreferrer" href=https://weibo.com/u/3848950217>
<i class="fab fa-weibo"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter>
<a class=text-white target=_blank rel="noopener noreferrer" href=https://twitter.com/zhange_zzg>
<i class="fab fa-twitter"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="Stack Overflow" aria-label="Stack Overflow">
<a class=text-white target=_blank rel="noopener noreferrer" href=https://stackoverflow.com>
<i class="fab fa-stack-overflow"></i>
</a>
</li>
<li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub>
<a class=text-white target=_blank rel="noopener noreferrer" href=https://github.com/infilos/infilos.com>
<i class="fab fa-github"></i>
</a>
</li>
</ul>
</div>
<div class="col-12 col-sm-4 text-center py-2 order-sm-2">
<small class=text-white>&copy; 2021 infilos.com All Rights Reserved</small>
</div>
</div>
</div>
</footer>
</div>
<script src=/js/popper.min.js integrity=sha384-ZMP7rVo3mIykV+2+9J3UJ46jBk0WLaUAdn689aCwoqbBJiSnjAK/l8WvCWPIPm49 crossorigin=anonymous></script>
<script src=/js/bootstrap.min.js integrity=sha384-ChfqqxuZUCnJSK3+MXmPNIyE6ZbWh2IMqE241rYiqJxyMiZ6OW/JmZQ5stwEULTy crossorigin=anonymous></script>
<script src=/js/main.min.5c74b870c6953931a705f390a49c7e4c0a842ec5c83b24354758dd674343ed0d.js integrity="sha256-XHS4cMaVOTGnBfOQpJx+TAqELsXIOyQ1R1jdZ0ND7Q0=" crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/docsearch.js@2.6.3/dist/cdn/docsearch.min.js></script>
<script>docsearch({apiKey:'123',indexName:'infilos_com',inputSelector:'.td-search-input',debug:!1})</script>
</body>
</html>